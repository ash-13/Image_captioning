{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** I will implement some of the \"Show and Tell: A Neural Image Caption Generator\", It has the same model as of us. It has CNN as an image “encoder”, by first pre-training it for an image classification task, for recognizing objects with its background followed by a language generating RNN. I am not using softmax to output decoder becuase of deterioration. This paper has both batch_size and embed_size 512. But I am using batch_size 64 and embed_size 512. If I don't gain results than I will change it!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** I am not chaning `transform_train` because they are enough to obtain results.\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** As we do not have a large database, weights of ResNet are not trainable. Others are all trainable.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** I am using Adam optimizer becuase it converges fast and best for the epochs I'm using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 410/414113 [00:00<01:40, 4098.32it/s]\u001b[A\n",
      "  0%|          | 798/414113 [00:00<01:42, 4028.00it/s]\u001b[A\n",
      "  0%|          | 1253/414113 [00:00<01:39, 4169.53it/s]\u001b[A\n",
      "  0%|          | 1705/414113 [00:00<01:36, 4267.18it/s]\u001b[A\n",
      "  1%|          | 2164/414113 [00:00<01:34, 4358.34it/s]\u001b[A\n",
      "  1%|          | 2608/414113 [00:00<01:33, 4381.39it/s]\u001b[A\n",
      "  1%|          | 3052/414113 [00:00<01:33, 4398.44it/s]\u001b[A\n",
      "  1%|          | 3502/414113 [00:00<01:32, 4425.95it/s]\u001b[A\n",
      "  1%|          | 3943/414113 [00:00<01:32, 4421.02it/s]\u001b[A\n",
      "  1%|          | 4399/414113 [00:01<01:31, 4461.51it/s]\u001b[A\n",
      "  1%|          | 4855/414113 [00:01<01:31, 4489.48it/s]\u001b[A\n",
      "  1%|▏         | 5315/414113 [00:01<01:30, 4520.60it/s]\u001b[A\n",
      "  1%|▏         | 5762/414113 [00:01<01:30, 4500.09it/s]\u001b[A\n",
      "  1%|▏         | 6209/414113 [00:01<01:31, 4469.01it/s]\u001b[A\n",
      "  2%|▏         | 6664/414113 [00:01<01:30, 4491.09it/s]\u001b[A\n",
      "  2%|▏         | 7112/414113 [00:01<01:31, 4460.74it/s]\u001b[A\n",
      "  2%|▏         | 7557/414113 [00:01<01:32, 4381.89it/s]\u001b[A\n",
      "  2%|▏         | 8013/414113 [00:01<01:31, 4433.63it/s]\u001b[A\n",
      "  2%|▏         | 8457/414113 [00:01<01:31, 4415.21it/s]\u001b[A\n",
      "  2%|▏         | 8902/414113 [00:02<01:31, 4424.04it/s]\u001b[A\n",
      "  2%|▏         | 9345/414113 [00:02<01:31, 4401.16it/s]\u001b[A\n",
      "  2%|▏         | 9803/414113 [00:02<01:30, 4449.45it/s]\u001b[A\n",
      "  2%|▏         | 10249/414113 [00:02<01:31, 4428.79it/s]\u001b[A\n",
      "  3%|▎         | 10695/414113 [00:02<01:30, 4436.84it/s]\u001b[A\n",
      "  3%|▎         | 11146/414113 [00:02<01:30, 4458.10it/s]\u001b[A\n",
      "  3%|▎         | 11592/414113 [00:02<01:31, 4413.03it/s]\u001b[A\n",
      "  3%|▎         | 12034/414113 [00:02<01:31, 4411.10it/s]\u001b[A\n",
      "  3%|▎         | 12477/414113 [00:02<01:30, 4416.43it/s]\u001b[A\n",
      "  3%|▎         | 12928/414113 [00:02<01:30, 4442.82it/s]\u001b[A\n",
      "  3%|▎         | 13384/414113 [00:03<01:29, 4475.35it/s]\u001b[A\n",
      "  3%|▎         | 13844/414113 [00:03<01:28, 4510.22it/s]\u001b[A\n",
      "  3%|▎         | 14296/414113 [00:03<01:29, 4484.90it/s]\u001b[A\n",
      "  4%|▎         | 14745/414113 [00:03<01:29, 4468.30it/s]\u001b[A\n",
      "  4%|▎         | 15192/414113 [00:03<01:29, 4441.77it/s]\u001b[A\n",
      "  4%|▍         | 15649/414113 [00:03<01:29, 4476.89it/s]\u001b[A\n",
      "  4%|▍         | 16097/414113 [00:03<01:29, 4459.37it/s]\u001b[A\n",
      "  4%|▍         | 16554/414113 [00:03<01:28, 4490.37it/s]\u001b[A\n",
      "  4%|▍         | 17004/414113 [00:03<01:28, 4468.17it/s]\u001b[A\n",
      "  4%|▍         | 17455/414113 [00:03<01:28, 4479.41it/s]\u001b[A\n",
      "  4%|▍         | 17904/414113 [00:04<01:28, 4458.72it/s]\u001b[A\n",
      "  4%|▍         | 18350/414113 [00:04<01:29, 4437.35it/s]\u001b[A\n",
      "  5%|▍         | 18794/414113 [00:04<01:29, 4421.49it/s]\u001b[A\n",
      "  5%|▍         | 19237/414113 [00:04<01:29, 4420.39it/s]\u001b[A\n",
      "  5%|▍         | 19680/414113 [00:04<01:29, 4420.85it/s]\u001b[A\n",
      "  5%|▍         | 20123/414113 [00:04<01:29, 4385.78it/s]\u001b[A\n",
      "  5%|▍         | 20570/414113 [00:04<01:29, 4408.43it/s]\u001b[A\n",
      "  5%|▌         | 21020/414113 [00:04<01:28, 4435.44it/s]\u001b[A\n",
      "  5%|▌         | 21465/414113 [00:04<01:28, 4438.66it/s]\u001b[A\n",
      "  5%|▌         | 21909/414113 [00:04<01:28, 4428.30it/s]\u001b[A\n",
      "  5%|▌         | 22366/414113 [00:05<01:27, 4468.79it/s]\u001b[A\n",
      "  6%|▌         | 22814/414113 [00:05<01:27, 4468.54it/s]\u001b[A\n",
      "  6%|▌         | 23261/414113 [00:05<01:27, 4444.62it/s]\u001b[A\n",
      "  6%|▌         | 23710/414113 [00:05<01:27, 4456.93it/s]\u001b[A\n",
      "  6%|▌         | 24156/414113 [00:05<01:28, 4387.28it/s]\u001b[A\n",
      "  6%|▌         | 24596/414113 [00:05<01:28, 4378.21it/s]\u001b[A\n",
      "  6%|▌         | 25045/414113 [00:05<01:28, 4410.33it/s]\u001b[A\n",
      "  6%|▌         | 25505/414113 [00:05<01:27, 4464.47it/s]\u001b[A\n",
      "  6%|▋         | 25955/414113 [00:05<01:26, 4472.44it/s]\u001b[A\n",
      "  6%|▋         | 26408/414113 [00:05<01:26, 4489.06it/s]\u001b[A\n",
      "  6%|▋         | 26868/414113 [00:06<01:25, 4519.66it/s]\u001b[A\n",
      "  7%|▋         | 27323/414113 [00:06<01:25, 4526.32it/s]\u001b[A\n",
      "  7%|▋         | 27791/414113 [00:06<01:24, 4568.72it/s]\u001b[A\n",
      "  7%|▋         | 28249/414113 [00:06<01:24, 4544.75it/s]\u001b[A\n",
      "  7%|▋         | 28716/414113 [00:06<01:24, 4580.60it/s]\u001b[A\n",
      "  7%|▋         | 29175/414113 [00:06<01:24, 4555.55it/s]\u001b[A\n",
      "  7%|▋         | 29631/414113 [00:06<01:24, 4547.17it/s]\u001b[A\n",
      "  7%|▋         | 30086/414113 [00:06<01:24, 4547.27it/s]\u001b[A\n",
      "  7%|▋         | 30541/414113 [00:06<01:24, 4533.55it/s]\u001b[A\n",
      "  7%|▋         | 31009/414113 [00:06<01:23, 4575.28it/s]\u001b[A\n",
      "  8%|▊         | 31467/414113 [00:07<01:23, 4562.96it/s]\u001b[A\n",
      "  8%|▊         | 31924/414113 [00:07<01:26, 4400.72it/s]\u001b[A\n",
      "  8%|▊         | 32384/414113 [00:07<01:25, 4457.71it/s]\u001b[A\n",
      "  8%|▊         | 32833/414113 [00:07<01:25, 4466.47it/s]\u001b[A\n",
      "  8%|▊         | 33281/414113 [00:07<01:25, 4462.79it/s]\u001b[A\n",
      "  8%|▊         | 33728/414113 [00:07<01:25, 4445.74it/s]\u001b[A\n",
      "  8%|▊         | 34174/414113 [00:07<01:25, 4449.98it/s]\u001b[A\n",
      "  8%|▊         | 34620/414113 [00:07<01:25, 4452.44it/s]\u001b[A\n",
      "  8%|▊         | 35066/414113 [00:07<01:25, 4444.85it/s]\u001b[A\n",
      "  9%|▊         | 35511/414113 [00:07<01:25, 4441.85it/s]\u001b[A\n",
      "  9%|▊         | 35956/414113 [00:08<01:25, 4439.20it/s]\u001b[A\n",
      "  9%|▉         | 36412/414113 [00:08<01:24, 4473.87it/s]\u001b[A\n",
      "  9%|▉         | 36861/414113 [00:08<01:24, 4478.01it/s]\u001b[A\n",
      "  9%|▉         | 37320/414113 [00:08<01:23, 4508.08it/s]\u001b[A\n",
      "  9%|▉         | 37771/414113 [00:08<01:23, 4496.26it/s]\u001b[A\n",
      "  9%|▉         | 38232/414113 [00:08<01:23, 4527.70it/s]\u001b[A\n",
      "  9%|▉         | 38689/414113 [00:08<01:22, 4539.14it/s]\u001b[A\n",
      "  9%|▉         | 39143/414113 [00:08<01:23, 4508.19it/s]\u001b[A\n",
      " 10%|▉         | 39603/414113 [00:08<01:22, 4532.70it/s]\u001b[A\n",
      " 10%|▉         | 40057/414113 [00:08<01:22, 4506.94it/s]\u001b[A\n",
      " 10%|▉         | 40511/414113 [00:09<01:22, 4515.86it/s]\u001b[A\n",
      " 10%|▉         | 40963/414113 [00:09<01:23, 4478.56it/s]\u001b[A\n",
      " 10%|█         | 41422/414113 [00:09<01:22, 4510.95it/s]\u001b[A\n",
      " 10%|█         | 41874/414113 [00:09<01:23, 4439.74it/s]\u001b[A\n",
      " 10%|█         | 42326/414113 [00:09<01:23, 4462.70it/s]\u001b[A\n",
      " 10%|█         | 42773/414113 [00:09<01:24, 4409.94it/s]\u001b[A\n",
      " 10%|█         | 43225/414113 [00:09<01:23, 4441.41it/s]\u001b[A\n",
      " 11%|█         | 43670/414113 [00:09<01:24, 4368.44it/s]\u001b[A\n",
      " 11%|█         | 44117/414113 [00:09<01:24, 4395.98it/s]\u001b[A\n",
      " 11%|█         | 44557/414113 [00:09<01:24, 4375.89it/s]\u001b[A\n",
      " 11%|█         | 45009/414113 [00:10<01:23, 4415.96it/s]\u001b[A\n",
      " 11%|█         | 45466/414113 [00:10<01:22, 4458.19it/s]\u001b[A\n",
      " 11%|█         | 45913/414113 [00:10<01:22, 4453.08it/s]\u001b[A\n",
      " 11%|█         | 46370/414113 [00:10<01:21, 4487.28it/s]\u001b[A\n",
      " 11%|█▏        | 46819/414113 [00:10<01:21, 4482.12it/s]\u001b[A\n",
      " 11%|█▏        | 47268/414113 [00:10<01:22, 4465.13it/s]\u001b[A\n",
      " 12%|█▏        | 47715/414113 [00:10<01:22, 4430.85it/s]\u001b[A\n",
      " 12%|█▏        | 48166/414113 [00:10<01:22, 4452.98it/s]\u001b[A\n",
      " 12%|█▏        | 48613/414113 [00:10<01:22, 4455.33it/s]\u001b[A\n",
      " 12%|█▏        | 49064/414113 [00:11<01:21, 4471.45it/s]\u001b[A\n",
      " 12%|█▏        | 49523/414113 [00:11<01:20, 4505.22it/s]\u001b[A\n",
      " 12%|█▏        | 49987/414113 [00:11<01:20, 4541.86it/s]\u001b[A\n",
      " 12%|█▏        | 50450/414113 [00:11<01:19, 4566.37it/s]\u001b[A\n",
      " 12%|█▏        | 50907/414113 [00:11<01:20, 4492.17it/s]\u001b[A\n",
      " 12%|█▏        | 51362/414113 [00:11<01:20, 4508.29it/s]\u001b[A\n",
      " 13%|█▎        | 51828/414113 [00:11<01:19, 4552.14it/s]\u001b[A\n",
      " 13%|█▎        | 52284/414113 [00:11<01:19, 4551.92it/s]\u001b[A\n",
      " 13%|█▎        | 52740/414113 [00:11<01:20, 4507.73it/s]\u001b[A\n",
      " 13%|█▎        | 53198/414113 [00:11<01:19, 4527.76it/s]\u001b[A\n",
      " 13%|█▎        | 53651/414113 [00:12<01:22, 4364.35it/s]\u001b[A\n",
      " 13%|█▎        | 54104/414113 [00:12<01:21, 4410.28it/s]\u001b[A\n",
      " 13%|█▎        | 54556/414113 [00:12<01:20, 4442.47it/s]\u001b[A\n",
      " 13%|█▎        | 55007/414113 [00:12<01:20, 4459.66it/s]\u001b[A\n",
      " 13%|█▎        | 55464/414113 [00:12<01:19, 4491.35it/s]\u001b[A\n",
      " 14%|█▎        | 55931/414113 [00:12<01:18, 4540.52it/s]\u001b[A\n",
      " 14%|█▎        | 56386/414113 [00:12<01:18, 4531.75it/s]\u001b[A\n",
      " 14%|█▎        | 56841/414113 [00:12<01:18, 4536.75it/s]\u001b[A\n",
      " 14%|█▍        | 57295/414113 [00:12<01:18, 4535.60it/s]\u001b[A\n",
      " 14%|█▍        | 57749/414113 [00:12<01:19, 4488.20it/s]\u001b[A\n",
      " 14%|█▍        | 58200/414113 [00:13<01:19, 4493.29it/s]\u001b[A\n",
      " 14%|█▍        | 58650/414113 [00:13<01:19, 4454.94it/s]\u001b[A\n",
      " 14%|█▍        | 59096/414113 [00:13<01:19, 4452.70it/s]\u001b[A\n",
      " 14%|█▍        | 59549/414113 [00:13<01:19, 4472.90it/s]\u001b[A\n",
      " 14%|█▍        | 60008/414113 [00:13<01:18, 4505.49it/s]\u001b[A\n",
      " 15%|█▍        | 60470/414113 [00:13<01:17, 4536.46it/s]\u001b[A\n",
      " 15%|█▍        | 60924/414113 [00:13<01:18, 4491.10it/s]\u001b[A\n",
      " 15%|█▍        | 61389/414113 [00:13<01:17, 4536.57it/s]\u001b[A\n",
      " 15%|█▍        | 61843/414113 [00:13<01:18, 4491.70it/s]\u001b[A\n",
      " 15%|█▌        | 62293/414113 [00:13<01:18, 4459.59it/s]\u001b[A\n",
      " 15%|█▌        | 62740/414113 [00:14<01:22, 4259.22it/s]\u001b[A\n",
      " 15%|█▌        | 63188/414113 [00:14<01:21, 4321.43it/s]\u001b[A\n",
      " 15%|█▌        | 63641/414113 [00:14<01:20, 4379.66it/s]\u001b[A\n",
      " 15%|█▌        | 64114/414113 [00:14<01:18, 4477.45it/s]\u001b[A\n",
      " 16%|█▌        | 64564/414113 [00:14<01:18, 4480.75it/s]\u001b[A\n",
      " 16%|█▌        | 65016/414113 [00:14<01:17, 4492.30it/s]\u001b[A\n",
      " 16%|█▌        | 65466/414113 [00:14<01:17, 4476.41it/s]\u001b[A\n",
      " 16%|█▌        | 65925/414113 [00:14<01:17, 4509.28it/s]\u001b[A\n",
      " 16%|█▌        | 66377/414113 [00:14<01:17, 4507.75it/s]\u001b[A\n",
      " 16%|█▌        | 66842/414113 [00:14<01:16, 4547.94it/s]\u001b[A\n",
      " 16%|█▋        | 67298/414113 [00:15<01:16, 4532.38it/s]\u001b[A\n",
      " 16%|█▋        | 67752/414113 [00:15<01:16, 4517.16it/s]\u001b[A\n",
      " 16%|█▋        | 68204/414113 [00:15<02:00, 2881.61it/s]\u001b[A\n",
      " 17%|█▋        | 68664/414113 [00:15<01:46, 3244.22it/s]\u001b[A\n",
      " 17%|█▋        | 69118/414113 [00:15<01:37, 3546.81it/s]\u001b[A\n",
      " 17%|█▋        | 69574/414113 [00:15<01:30, 3799.28it/s]\u001b[A\n",
      " 17%|█▋        | 70028/414113 [00:15<01:26, 3992.96it/s]\u001b[A\n",
      " 17%|█▋        | 70502/414113 [00:15<01:22, 4190.29it/s]\u001b[A\n",
      " 17%|█▋        | 70958/414113 [00:16<01:19, 4292.98it/s]\u001b[A\n",
      " 17%|█▋        | 71420/414113 [00:16<01:18, 4385.25it/s]\u001b[A\n",
      " 17%|█▋        | 71884/414113 [00:16<01:16, 4456.58it/s]\u001b[A\n",
      " 17%|█▋        | 72348/414113 [00:16<01:15, 4508.06it/s]\u001b[A\n",
      " 18%|█▊        | 72806/414113 [00:16<01:15, 4518.22it/s]\u001b[A\n",
      " 18%|█▊        | 73263/414113 [00:16<01:16, 4429.75it/s]\u001b[A\n",
      " 18%|█▊        | 73726/414113 [00:16<01:15, 4486.75it/s]\u001b[A\n",
      " 18%|█▊        | 74178/414113 [00:16<01:15, 4491.03it/s]\u001b[A\n",
      " 18%|█▊        | 74632/414113 [00:16<01:15, 4503.69it/s]\u001b[A\n",
      " 18%|█▊        | 75084/414113 [00:16<01:15, 4468.74it/s]\u001b[A\n",
      " 18%|█▊        | 75532/414113 [00:17<01:16, 4443.73it/s]\u001b[A\n",
      " 18%|█▊        | 75978/414113 [00:17<01:16, 4424.04it/s]\u001b[A\n",
      " 18%|█▊        | 76427/414113 [00:17<01:16, 4441.19it/s]\u001b[A\n",
      " 19%|█▊        | 76878/414113 [00:17<01:15, 4459.29it/s]\u001b[A\n",
      " 19%|█▊        | 77325/414113 [00:17<01:15, 4447.35it/s]\u001b[A\n",
      " 19%|█▉        | 77771/414113 [00:17<01:15, 4451.04it/s]\u001b[A\n",
      " 19%|█▉        | 78217/414113 [00:17<01:16, 4410.15it/s]\u001b[A\n",
      " 19%|█▉        | 78659/414113 [00:17<01:16, 4369.22it/s]\u001b[A\n",
      " 19%|█▉        | 79104/414113 [00:17<01:16, 4391.16it/s]\u001b[A\n",
      " 19%|█▉        | 79547/414113 [00:17<01:16, 4401.58it/s]\u001b[A\n",
      " 19%|█▉        | 79989/414113 [00:18<01:15, 4405.36it/s]\u001b[A\n",
      " 19%|█▉        | 80443/414113 [00:18<01:15, 4444.90it/s]\u001b[A\n",
      " 20%|█▉        | 80888/414113 [00:18<01:14, 4443.81it/s]\u001b[A\n",
      " 20%|█▉        | 81348/414113 [00:18<01:14, 4487.41it/s]\u001b[A\n",
      " 20%|█▉        | 81797/414113 [00:18<01:14, 4474.87it/s]\u001b[A\n",
      " 20%|█▉        | 82246/414113 [00:18<01:14, 4478.82it/s]\u001b[A\n",
      " 20%|█▉        | 82705/414113 [00:18<01:13, 4510.60it/s]\u001b[A\n",
      " 20%|██        | 83159/414113 [00:18<01:13, 4516.78it/s]\u001b[A\n",
      " 20%|██        | 83615/414113 [00:18<01:12, 4528.55it/s]\u001b[A\n",
      " 20%|██        | 84068/414113 [00:18<01:13, 4500.21it/s]\u001b[A\n",
      " 20%|██        | 84519/414113 [00:19<01:14, 4447.93it/s]\u001b[A\n",
      " 21%|██        | 84964/414113 [00:19<01:15, 4380.92it/s]\u001b[A\n",
      " 21%|██        | 85406/414113 [00:19<01:14, 4391.30it/s]\u001b[A\n",
      " 21%|██        | 85849/414113 [00:19<01:14, 4399.15it/s]\u001b[A\n",
      " 21%|██        | 86298/414113 [00:19<01:14, 4424.99it/s]\u001b[A\n",
      " 21%|██        | 86743/414113 [00:19<01:13, 4430.66it/s]\u001b[A\n",
      " 21%|██        | 87208/414113 [00:19<01:12, 4491.67it/s]\u001b[A\n",
      " 21%|██        | 87671/414113 [00:19<01:12, 4531.55it/s]\u001b[A\n",
      " 21%|██▏       | 88127/414113 [00:19<01:11, 4537.83it/s]\u001b[A\n",
      " 21%|██▏       | 88598/414113 [00:19<01:10, 4586.39it/s]\u001b[A\n",
      " 22%|██▏       | 89057/414113 [00:20<01:11, 4574.72it/s]\u001b[A\n",
      " 22%|██▏       | 89528/414113 [00:20<01:10, 4613.38it/s]\u001b[A\n",
      " 22%|██▏       | 89997/414113 [00:20<01:09, 4635.81it/s]\u001b[A\n",
      " 22%|██▏       | 90462/414113 [00:20<01:09, 4638.72it/s]\u001b[A\n",
      " 22%|██▏       | 90929/414113 [00:20<01:09, 4646.16it/s]\u001b[A\n",
      " 22%|██▏       | 91396/414113 [00:20<01:09, 4650.63it/s]\u001b[A\n",
      " 22%|██▏       | 91867/414113 [00:20<01:09, 4667.15it/s]\u001b[A\n",
      " 22%|██▏       | 92334/414113 [00:20<01:09, 4642.16it/s]\u001b[A\n",
      " 22%|██▏       | 92799/414113 [00:20<01:09, 4631.65it/s]\u001b[A\n",
      " 23%|██▎       | 93263/414113 [00:21<01:09, 4616.88it/s]\u001b[A\n",
      " 23%|██▎       | 93725/414113 [00:21<01:10, 4555.92it/s]\u001b[A\n",
      " 23%|██▎       | 94193/414113 [00:21<01:09, 4592.21it/s]\u001b[A\n",
      " 23%|██▎       | 94657/414113 [00:21<01:09, 4603.75it/s]\u001b[A\n",
      " 23%|██▎       | 95118/414113 [00:21<01:10, 4525.76it/s]\u001b[A\n",
      " 23%|██▎       | 95571/414113 [00:21<01:10, 4514.80it/s]\u001b[A\n",
      " 23%|██▎       | 96023/414113 [00:21<01:10, 4496.08it/s]\u001b[A\n",
      " 23%|██▎       | 96480/414113 [00:21<01:10, 4516.10it/s]\u001b[A\n",
      " 23%|██▎       | 96933/414113 [00:21<01:10, 4519.87it/s]\u001b[A\n",
      " 24%|██▎       | 97386/414113 [00:21<01:11, 4402.08it/s]\u001b[A\n",
      " 24%|██▎       | 97844/414113 [00:22<01:11, 4453.69it/s]\u001b[A\n",
      " 24%|██▎       | 98291/414113 [00:22<01:11, 4436.21it/s]\u001b[A\n",
      " 24%|██▍       | 98736/414113 [00:22<01:11, 4439.91it/s]\u001b[A\n",
      " 24%|██▍       | 99181/414113 [00:22<01:10, 4439.16it/s]\u001b[A\n",
      " 24%|██▍       | 99626/414113 [00:22<01:10, 4436.88it/s]\u001b[A\n",
      " 24%|██▍       | 100077/414113 [00:22<01:10, 4455.99it/s]\u001b[A\n",
      " 24%|██▍       | 100523/414113 [00:22<01:10, 4436.47it/s]\u001b[A\n",
      " 24%|██▍       | 100968/414113 [00:22<01:10, 4439.98it/s]\u001b[A\n",
      " 24%|██▍       | 101413/414113 [00:22<01:10, 4409.19it/s]\u001b[A\n",
      " 25%|██▍       | 101855/414113 [00:22<01:11, 4389.46it/s]\u001b[A\n",
      " 25%|██▍       | 102298/414113 [00:23<01:10, 4400.24it/s]\u001b[A\n",
      " 25%|██▍       | 102756/414113 [00:23<01:09, 4452.02it/s]\u001b[A\n",
      " 25%|██▍       | 103222/414113 [00:23<01:08, 4509.82it/s]\u001b[A\n",
      " 25%|██▌       | 103691/414113 [00:23<01:08, 4561.85it/s]\u001b[A\n",
      " 25%|██▌       | 104155/414113 [00:23<01:07, 4582.22it/s]\u001b[A\n",
      " 25%|██▌       | 104614/414113 [00:23<01:08, 4513.02it/s]\u001b[A\n",
      " 25%|██▌       | 105066/414113 [00:23<01:08, 4479.87it/s]\u001b[A\n",
      " 25%|██▌       | 105515/414113 [00:23<01:09, 4470.51it/s]\u001b[A\n",
      " 26%|██▌       | 105963/414113 [00:23<01:09, 4433.88it/s]\u001b[A\n",
      " 26%|██▌       | 106418/414113 [00:23<01:08, 4467.17it/s]\u001b[A\n",
      " 26%|██▌       | 106865/414113 [00:24<01:09, 4400.62it/s]\u001b[A\n",
      " 26%|██▌       | 107308/414113 [00:24<01:09, 4407.97it/s]\u001b[A\n",
      " 26%|██▌       | 107762/414113 [00:24<01:08, 4446.13it/s]\u001b[A\n",
      " 26%|██▌       | 108207/414113 [00:24<01:08, 4440.29it/s]\u001b[A\n",
      " 26%|██▌       | 108671/414113 [00:24<01:07, 4498.26it/s]\u001b[A\n",
      " 26%|██▋       | 109122/414113 [00:24<01:07, 4489.10it/s]\u001b[A\n",
      " 26%|██▋       | 109580/414113 [00:24<01:07, 4514.54it/s]\u001b[A\n",
      " 27%|██▋       | 110032/414113 [00:24<01:07, 4511.50it/s]\u001b[A\n",
      " 27%|██▋       | 110488/414113 [00:24<01:07, 4523.76it/s]\u001b[A\n",
      " 27%|██▋       | 110952/414113 [00:24<01:06, 4555.67it/s]\u001b[A\n",
      " 27%|██▋       | 111416/414113 [00:25<01:06, 4579.84it/s]\u001b[A\n",
      " 27%|██▋       | 111882/414113 [00:25<01:05, 4601.38it/s]\u001b[A\n",
      " 27%|██▋       | 112345/414113 [00:25<01:05, 4609.81it/s]\u001b[A\n",
      " 27%|██▋       | 112810/414113 [00:25<01:05, 4620.12it/s]\u001b[A\n",
      " 27%|██▋       | 113283/414113 [00:25<01:04, 4650.50it/s]\u001b[A\n",
      " 27%|██▋       | 113749/414113 [00:25<01:04, 4624.66it/s]\u001b[A\n",
      " 28%|██▊       | 114212/414113 [00:25<01:05, 4586.60it/s]\u001b[A\n",
      " 28%|██▊       | 114671/414113 [00:25<01:05, 4553.09it/s]\u001b[A\n",
      " 28%|██▊       | 115127/414113 [00:25<01:05, 4541.11it/s]\u001b[A\n",
      " 28%|██▊       | 115585/414113 [00:25<01:05, 4552.24it/s]\u001b[A\n",
      " 28%|██▊       | 116041/414113 [00:26<01:05, 4540.23it/s]\u001b[A\n",
      " 28%|██▊       | 116503/414113 [00:26<01:05, 4562.27it/s]\u001b[A\n",
      " 28%|██▊       | 116963/414113 [00:26<01:04, 4572.72it/s]\u001b[A\n",
      " 28%|██▊       | 117421/414113 [00:26<01:05, 4521.02it/s]\u001b[A\n",
      " 28%|██▊       | 117874/414113 [00:26<01:08, 4327.00it/s]\u001b[A\n",
      " 29%|██▊       | 118325/414113 [00:26<01:07, 4380.19it/s]\u001b[A\n",
      " 29%|██▊       | 118777/414113 [00:26<01:06, 4418.56it/s]\u001b[A\n",
      " 29%|██▉       | 119239/414113 [00:26<01:05, 4474.49it/s]\u001b[A\n",
      " 29%|██▉       | 119688/414113 [00:26<01:06, 4455.81it/s]\u001b[A\n",
      " 29%|██▉       | 120152/414113 [00:26<01:05, 4509.44it/s]\u001b[A\n",
      " 29%|██▉       | 120613/414113 [00:27<01:04, 4538.39it/s]\u001b[A\n",
      " 29%|██▉       | 121086/414113 [00:27<01:03, 4592.19it/s]\u001b[A\n",
      " 29%|██▉       | 121546/414113 [00:27<01:03, 4583.53it/s]\u001b[A\n",
      " 29%|██▉       | 122005/414113 [00:27<01:03, 4574.33it/s]\u001b[A\n",
      " 30%|██▉       | 122465/414113 [00:27<01:03, 4579.73it/s]\u001b[A\n",
      " 30%|██▉       | 122928/414113 [00:27<01:03, 4593.37it/s]\u001b[A\n",
      " 30%|██▉       | 123388/414113 [00:27<01:03, 4566.29it/s]\u001b[A\n",
      " 30%|██▉       | 123845/414113 [00:27<01:03, 4561.39it/s]\u001b[A\n",
      " 30%|███       | 124311/414113 [00:27<01:03, 4589.55it/s]\u001b[A\n",
      " 30%|███       | 124771/414113 [00:27<01:03, 4579.57it/s]\u001b[A\n",
      " 30%|███       | 125230/414113 [00:28<01:03, 4574.71it/s]\u001b[A\n",
      " 30%|███       | 125697/414113 [00:28<01:02, 4602.54it/s]\u001b[A\n",
      " 30%|███       | 126158/414113 [00:28<01:02, 4582.44it/s]\u001b[A\n",
      " 31%|███       | 126617/414113 [00:28<01:03, 4538.93it/s]\u001b[A\n",
      " 31%|███       | 127078/414113 [00:28<01:02, 4557.85it/s]\u001b[A\n",
      " 31%|███       | 127540/414113 [00:28<01:02, 4574.34it/s]\u001b[A\n",
      " 31%|███       | 127998/414113 [00:28<01:03, 4525.79it/s]\u001b[A\n",
      " 31%|███       | 128452/414113 [00:28<01:03, 4529.51it/s]\u001b[A\n",
      " 31%|███       | 128906/414113 [00:28<01:03, 4506.49it/s]\u001b[A\n",
      " 31%|███       | 129361/414113 [00:29<01:03, 4519.02it/s]\u001b[A\n",
      " 31%|███▏      | 129826/414113 [00:29<01:02, 4557.20it/s]\u001b[A\n",
      " 31%|███▏      | 130292/414113 [00:29<01:01, 4584.51it/s]\u001b[A\n",
      " 32%|███▏      | 130751/414113 [00:29<01:03, 4497.16it/s]\u001b[A\n",
      " 32%|███▏      | 131210/414113 [00:29<01:02, 4522.29it/s]\u001b[A\n",
      " 32%|███▏      | 131668/414113 [00:29<01:02, 4538.58it/s]\u001b[A\n",
      " 32%|███▏      | 132124/414113 [00:29<01:02, 4543.69it/s]\u001b[A\n",
      " 32%|███▏      | 132590/414113 [00:29<01:01, 4576.20it/s]\u001b[A\n",
      " 32%|███▏      | 133053/414113 [00:29<01:01, 4589.48it/s]\u001b[A\n",
      " 32%|███▏      | 133513/414113 [00:29<01:01, 4584.36it/s]\u001b[A\n",
      " 32%|███▏      | 133972/414113 [00:30<01:01, 4583.05it/s]\u001b[A\n",
      " 32%|███▏      | 134431/414113 [00:30<01:01, 4576.12it/s]\u001b[A\n",
      " 33%|███▎      | 134889/414113 [00:30<01:01, 4575.69it/s]\u001b[A\n",
      " 33%|███▎      | 135356/414113 [00:30<01:00, 4602.44it/s]\u001b[A\n",
      " 33%|███▎      | 135828/414113 [00:30<01:00, 4634.72it/s]\u001b[A\n",
      " 33%|███▎      | 136293/414113 [00:30<00:59, 4638.28it/s]\u001b[A\n",
      " 33%|███▎      | 136757/414113 [00:30<01:00, 4605.91it/s]\u001b[A\n",
      " 33%|███▎      | 137218/414113 [00:30<01:00, 4562.62it/s]\u001b[A\n",
      " 33%|███▎      | 137681/414113 [00:30<01:00, 4579.98it/s]\u001b[A\n",
      " 33%|███▎      | 138140/414113 [00:30<01:00, 4579.66it/s]\u001b[A\n",
      " 33%|███▎      | 138599/414113 [00:31<01:00, 4571.50it/s]\u001b[A\n",
      " 34%|███▎      | 139057/414113 [00:31<01:00, 4545.52it/s]\u001b[A\n",
      " 34%|███▎      | 139519/414113 [00:31<01:00, 4567.27it/s]\u001b[A\n",
      " 34%|███▍      | 139979/414113 [00:31<00:59, 4574.86it/s]\u001b[A\n",
      " 34%|███▍      | 140437/414113 [00:31<01:00, 4541.23it/s]\u001b[A\n",
      " 34%|███▍      | 140895/414113 [00:31<01:00, 4552.76it/s]\u001b[A\n",
      " 34%|███▍      | 141351/414113 [00:31<01:00, 4531.51it/s]\u001b[A\n",
      " 34%|███▍      | 141808/414113 [00:31<00:59, 4541.22it/s]\u001b[A\n",
      " 34%|███▍      | 142263/414113 [00:31<01:00, 4526.74it/s]\u001b[A\n",
      " 34%|███▍      | 142720/414113 [00:31<00:59, 4539.37it/s]\u001b[A\n",
      " 35%|███▍      | 143174/414113 [00:32<00:59, 4516.62it/s]\u001b[A\n",
      " 35%|███▍      | 143641/414113 [00:32<00:59, 4560.12it/s]\u001b[A\n",
      " 35%|███▍      | 144098/414113 [00:32<00:59, 4537.48it/s]\u001b[A\n",
      " 35%|███▍      | 144566/414113 [00:32<00:58, 4576.65it/s]\u001b[A\n",
      " 35%|███▌      | 145024/414113 [00:32<00:58, 4571.76it/s]\u001b[A\n",
      " 35%|███▌      | 145487/414113 [00:32<00:58, 4587.67it/s]\u001b[A\n",
      " 35%|███▌      | 145947/414113 [00:32<00:58, 4588.53it/s]\u001b[A\n",
      " 35%|███▌      | 146406/414113 [00:32<00:58, 4562.35it/s]\u001b[A\n",
      " 35%|███▌      | 146863/414113 [00:32<00:58, 4546.69it/s]\u001b[A\n",
      " 36%|███▌      | 147328/414113 [00:32<00:58, 4576.43it/s]\u001b[A\n",
      " 36%|███▌      | 147786/414113 [00:33<00:58, 4527.81it/s]\u001b[A\n",
      " 36%|███▌      | 148246/414113 [00:33<00:58, 4548.39it/s]\u001b[A\n",
      " 36%|███▌      | 148707/414113 [00:33<00:58, 4565.50it/s]\u001b[A\n",
      " 36%|███▌      | 149164/414113 [00:33<00:58, 4532.24it/s]\u001b[A\n",
      " 36%|███▌      | 149618/414113 [00:33<00:59, 4453.09it/s]\u001b[A\n",
      " 36%|███▌      | 150083/414113 [00:33<00:58, 4508.48it/s]\u001b[A\n",
      " 36%|███▋      | 150554/414113 [00:33<00:57, 4565.16it/s]\u001b[A\n",
      " 36%|███▋      | 151020/414113 [00:33<00:57, 4590.80it/s]\u001b[A\n",
      " 37%|███▋      | 151480/414113 [00:33<00:57, 4583.47it/s]\u001b[A\n",
      " 37%|███▋      | 151947/414113 [00:33<00:56, 4607.51it/s]\u001b[A\n",
      " 37%|███▋      | 152409/414113 [00:34<00:56, 4611.13it/s]\u001b[A\n",
      " 37%|███▋      | 152882/414113 [00:34<00:56, 4646.03it/s]\u001b[A\n",
      " 37%|███▋      | 153353/414113 [00:34<00:55, 4662.12it/s]\u001b[A\n",
      " 37%|███▋      | 153822/414113 [00:34<00:55, 4668.37it/s]\u001b[A\n",
      " 37%|███▋      | 154295/414113 [00:34<00:55, 4684.07it/s]\u001b[A\n",
      " 37%|███▋      | 154764/414113 [00:34<00:55, 4663.69it/s]\u001b[A\n",
      " 37%|███▋      | 155234/414113 [00:34<00:55, 4669.33it/s]\u001b[A\n",
      " 38%|███▊      | 155702/414113 [00:34<00:55, 4671.29it/s]\u001b[A\n",
      " 38%|███▊      | 156170/414113 [00:34<00:55, 4664.52it/s]\u001b[A\n",
      " 38%|███▊      | 156644/414113 [00:34<00:54, 4686.39it/s]\u001b[A\n",
      " 38%|███▊      | 157113/414113 [00:35<00:54, 4677.42it/s]\u001b[A\n",
      " 38%|███▊      | 157581/414113 [00:35<00:55, 4658.43it/s]\u001b[A\n",
      " 38%|███▊      | 158055/414113 [00:35<00:54, 4681.82it/s]\u001b[A\n",
      " 38%|███▊      | 158524/414113 [00:35<00:54, 4664.50it/s]\u001b[A\n",
      " 38%|███▊      | 158991/414113 [00:35<00:54, 4665.11it/s]\u001b[A\n",
      " 39%|███▊      | 159461/414113 [00:35<00:54, 4675.32it/s]\u001b[A\n",
      " 39%|███▊      | 159935/414113 [00:35<00:54, 4693.56it/s]\u001b[A\n",
      " 39%|███▊      | 160406/414113 [00:35<00:54, 4695.71it/s]\u001b[A\n",
      " 39%|███▉      | 160876/414113 [00:35<00:54, 4682.63it/s]\u001b[A\n",
      " 39%|███▉      | 161352/414113 [00:35<00:53, 4704.71it/s]\u001b[A\n",
      " 39%|███▉      | 161823/414113 [00:36<00:53, 4697.43it/s]\u001b[A\n",
      " 39%|███▉      | 162303/414113 [00:36<00:53, 4727.63it/s]\u001b[A\n",
      " 39%|███▉      | 162779/414113 [00:36<00:53, 4736.37it/s]\u001b[A\n",
      " 39%|███▉      | 163253/414113 [00:36<00:53, 4711.30it/s]\u001b[A\n",
      " 40%|███▉      | 163728/414113 [00:36<00:53, 4721.44it/s]\u001b[A\n",
      " 40%|███▉      | 164201/414113 [00:36<00:53, 4688.21it/s]\u001b[A\n",
      " 40%|███▉      | 164670/414113 [00:36<00:54, 4611.58it/s]\u001b[A\n",
      " 40%|███▉      | 165132/414113 [00:36<00:54, 4585.27it/s]\u001b[A\n",
      " 40%|███▉      | 165591/414113 [00:36<00:54, 4561.68it/s]\u001b[A\n",
      " 40%|████      | 166048/414113 [00:36<00:55, 4464.64it/s]\u001b[A\n",
      " 40%|████      | 166496/414113 [00:37<00:55, 4454.67it/s]\u001b[A\n",
      " 40%|████      | 166955/414113 [00:37<00:54, 4494.42it/s]\u001b[A\n",
      " 40%|████      | 167417/414113 [00:37<00:54, 4529.89it/s]\u001b[A\n",
      " 41%|████      | 167883/414113 [00:37<00:53, 4566.48it/s]\u001b[A\n",
      " 41%|████      | 168340/414113 [00:37<00:53, 4559.72it/s]\u001b[A\n",
      " 41%|████      | 168797/414113 [00:37<01:30, 2712.55it/s]\u001b[A\n",
      " 41%|████      | 169252/414113 [00:37<01:19, 3085.45it/s]\u001b[A\n",
      " 41%|████      | 169703/414113 [00:38<01:11, 3406.86it/s]\u001b[A\n",
      " 41%|████      | 170149/414113 [00:38<01:06, 3664.70it/s]\u001b[A\n",
      " 41%|████      | 170613/414113 [00:38<01:02, 3910.45it/s]\u001b[A\n",
      " 41%|████▏     | 171062/414113 [00:38<00:59, 4066.26it/s]\u001b[A\n",
      " 41%|████▏     | 171521/414113 [00:38<00:57, 4210.08it/s]\u001b[A\n",
      " 42%|████▏     | 171966/414113 [00:38<00:56, 4277.59it/s]\u001b[A\n",
      " 42%|████▏     | 172410/414113 [00:38<00:55, 4323.46it/s]\u001b[A\n",
      " 42%|████▏     | 172854/414113 [00:38<00:55, 4353.08it/s]\u001b[A\n",
      " 42%|████▏     | 173298/414113 [00:38<00:55, 4328.91it/s]\u001b[A\n",
      " 42%|████▏     | 173738/414113 [00:38<00:55, 4349.31it/s]\u001b[A\n",
      " 42%|████▏     | 174177/414113 [00:39<00:55, 4331.28it/s]\u001b[A\n",
      " 42%|████▏     | 174623/414113 [00:39<00:54, 4366.33it/s]\u001b[A\n",
      " 42%|████▏     | 175062/414113 [00:39<00:54, 4355.88it/s]\u001b[A\n",
      " 42%|████▏     | 175500/414113 [00:39<00:54, 4348.90it/s]\u001b[A\n",
      " 42%|████▏     | 175945/414113 [00:39<00:54, 4377.44it/s]\u001b[A\n",
      " 43%|████▎     | 176384/414113 [00:39<00:54, 4375.36it/s]\u001b[A\n",
      " 43%|████▎     | 176834/414113 [00:39<00:53, 4408.76it/s]\u001b[A\n",
      " 43%|████▎     | 177276/414113 [00:39<00:53, 4408.03it/s]\u001b[A\n",
      " 43%|████▎     | 177725/414113 [00:39<00:53, 4431.30it/s]\u001b[A\n",
      " 43%|████▎     | 178169/414113 [00:39<00:55, 4255.49it/s]\u001b[A\n",
      " 43%|████▎     | 178610/414113 [00:40<00:54, 4299.70it/s]\u001b[A\n",
      " 43%|████▎     | 179044/414113 [00:40<00:54, 4310.67it/s]\u001b[A\n",
      " 43%|████▎     | 179489/414113 [00:40<00:53, 4348.61it/s]\u001b[A\n",
      " 43%|████▎     | 179936/414113 [00:40<00:53, 4383.05it/s]\u001b[A\n",
      " 44%|████▎     | 180375/414113 [00:40<00:53, 4359.26it/s]\u001b[A\n",
      " 44%|████▎     | 180824/414113 [00:40<00:53, 4395.32it/s]\u001b[A\n",
      " 44%|████▍     | 181290/414113 [00:40<00:52, 4469.35it/s]\u001b[A\n",
      " 44%|████▍     | 181754/414113 [00:40<00:51, 4516.63it/s]\u001b[A\n",
      " 44%|████▍     | 182208/414113 [00:40<00:51, 4523.31it/s]\u001b[A\n",
      " 44%|████▍     | 182663/414113 [00:40<00:51, 4528.28it/s]\u001b[A\n",
      " 44%|████▍     | 183122/414113 [00:41<00:50, 4545.94it/s]\u001b[A\n",
      " 44%|████▍     | 183577/414113 [00:41<00:50, 4542.77it/s]\u001b[A\n",
      " 44%|████▍     | 184041/414113 [00:41<00:50, 4571.51it/s]\u001b[A\n",
      " 45%|████▍     | 184506/414113 [00:41<00:50, 4592.07it/s]\u001b[A\n",
      " 45%|████▍     | 184979/414113 [00:41<00:49, 4630.34it/s]\u001b[A\n",
      " 45%|████▍     | 185444/414113 [00:41<00:49, 4633.60it/s]\u001b[A\n",
      " 45%|████▍     | 185909/414113 [00:41<00:49, 4636.11it/s]\u001b[A\n",
      " 45%|████▌     | 186377/414113 [00:41<00:48, 4647.81it/s]\u001b[A\n",
      " 45%|████▌     | 186845/414113 [00:41<00:48, 4656.45it/s]\u001b[A\n",
      " 45%|████▌     | 187311/414113 [00:41<00:49, 4596.39it/s]\u001b[A\n",
      " 45%|████▌     | 187771/414113 [00:42<00:49, 4552.86it/s]\u001b[A\n",
      " 45%|████▌     | 188227/414113 [00:42<00:49, 4529.23it/s]\u001b[A\n",
      " 46%|████▌     | 188681/414113 [00:42<00:49, 4531.99it/s]\u001b[A\n",
      " 46%|████▌     | 189135/414113 [00:42<00:49, 4517.43it/s]\u001b[A\n",
      " 46%|████▌     | 189587/414113 [00:42<00:49, 4492.94it/s]\u001b[A\n",
      " 46%|████▌     | 190038/414113 [00:42<00:49, 4495.35it/s]\u001b[A\n",
      " 46%|████▌     | 190488/414113 [00:42<00:49, 4494.95it/s]\u001b[A\n",
      " 46%|████▌     | 190938/414113 [00:42<00:49, 4478.21it/s]\u001b[A\n",
      " 46%|████▌     | 191386/414113 [00:42<00:51, 4320.26it/s]\u001b[A\n",
      " 46%|████▋     | 191845/414113 [00:42<00:50, 4397.17it/s]\u001b[A\n",
      " 46%|████▋     | 192294/414113 [00:43<00:50, 4423.69it/s]\u001b[A\n",
      " 47%|████▋     | 192743/414113 [00:43<00:49, 4442.62it/s]\u001b[A\n",
      " 47%|████▋     | 193188/414113 [00:43<00:50, 4401.70it/s]\u001b[A\n",
      " 47%|████▋     | 193631/414113 [00:43<00:50, 4407.62it/s]\u001b[A\n",
      " 47%|████▋     | 194078/414113 [00:43<00:49, 4426.14it/s]\u001b[A\n",
      " 47%|████▋     | 194521/414113 [00:43<00:50, 4391.44it/s]\u001b[A\n",
      " 47%|████▋     | 194961/414113 [00:43<00:50, 4374.45it/s]\u001b[A\n",
      " 47%|████▋     | 195417/414113 [00:43<00:49, 4427.76it/s]\u001b[A\n",
      " 47%|████▋     | 195861/414113 [00:43<00:49, 4392.00it/s]\u001b[A\n",
      " 47%|████▋     | 196313/414113 [00:43<00:49, 4428.42it/s]\u001b[A\n",
      " 48%|████▊     | 196757/414113 [00:44<00:49, 4424.01it/s]\u001b[A\n",
      " 48%|████▊     | 197200/414113 [00:44<00:49, 4418.19it/s]\u001b[A\n",
      " 48%|████▊     | 197651/414113 [00:44<00:48, 4443.49it/s]\u001b[A\n",
      " 48%|████▊     | 198116/414113 [00:44<00:47, 4501.24it/s]\u001b[A\n",
      " 48%|████▊     | 198587/414113 [00:44<00:47, 4558.96it/s]\u001b[A\n",
      " 48%|████▊     | 199051/414113 [00:44<00:46, 4582.36it/s]\u001b[A\n",
      " 48%|████▊     | 199513/414113 [00:44<00:46, 4593.52it/s]\u001b[A\n",
      " 48%|████▊     | 199973/414113 [00:44<00:46, 4567.38it/s]\u001b[A\n",
      " 48%|████▊     | 200437/414113 [00:44<00:46, 4587.44it/s]\u001b[A\n",
      " 49%|████▊     | 200902/414113 [00:44<00:46, 4603.58it/s]\u001b[A\n",
      " 49%|████▊     | 201367/414113 [00:45<00:46, 4615.63it/s]\u001b[A\n",
      " 49%|████▊     | 201833/414113 [00:45<00:45, 4626.84it/s]\u001b[A\n",
      " 49%|████▉     | 202296/414113 [00:45<00:45, 4626.60it/s]\u001b[A\n",
      " 49%|████▉     | 202759/414113 [00:45<00:45, 4618.28it/s]\u001b[A\n",
      " 49%|████▉     | 203226/414113 [00:45<00:45, 4632.50it/s]\u001b[A\n",
      " 49%|████▉     | 203690/414113 [00:45<00:45, 4620.41it/s]\u001b[A\n",
      " 49%|████▉     | 204162/414113 [00:45<00:45, 4649.32it/s]\u001b[A\n",
      " 49%|████▉     | 204632/414113 [00:45<00:44, 4663.87it/s]\u001b[A\n",
      " 50%|████▉     | 205099/414113 [00:45<00:45, 4631.67it/s]\u001b[A\n",
      " 50%|████▉     | 205563/414113 [00:45<00:45, 4609.23it/s]\u001b[A\n",
      " 50%|████▉     | 206029/414113 [00:46<00:45, 4623.10it/s]\u001b[A\n",
      " 50%|████▉     | 206492/414113 [00:46<00:44, 4613.84it/s]\u001b[A\n",
      " 50%|████▉     | 206954/414113 [00:46<00:45, 4584.24it/s]\u001b[A\n",
      " 50%|█████     | 207415/414113 [00:46<00:45, 4590.96it/s]\u001b[A\n",
      " 50%|█████     | 207883/414113 [00:46<00:44, 4616.39it/s]\u001b[A\n",
      " 50%|█████     | 208345/414113 [00:46<00:44, 4615.97it/s]\u001b[A\n",
      " 50%|█████     | 208812/414113 [00:46<00:44, 4631.63it/s]\u001b[A\n",
      " 51%|█████     | 209276/414113 [00:46<00:44, 4628.86it/s]\u001b[A\n",
      " 51%|█████     | 209744/414113 [00:46<00:44, 4642.04it/s]\u001b[A\n",
      " 51%|█████     | 210215/414113 [00:46<00:43, 4659.27it/s]\u001b[A\n",
      " 51%|█████     | 210681/414113 [00:47<00:43, 4632.89it/s]\u001b[A\n",
      " 51%|█████     | 211145/414113 [00:47<00:44, 4591.36it/s]\u001b[A\n",
      " 51%|█████     | 211605/414113 [00:47<00:44, 4515.22it/s]\u001b[A\n",
      " 51%|█████     | 212080/414113 [00:47<00:44, 4580.74it/s]\u001b[A\n",
      " 51%|█████▏    | 212539/414113 [00:47<00:44, 4575.98it/s]\u001b[A\n",
      " 51%|█████▏    | 213015/414113 [00:47<00:43, 4626.98it/s]\u001b[A\n",
      " 52%|█████▏    | 213480/414113 [00:47<00:43, 4630.64it/s]\u001b[A\n",
      " 52%|█████▏    | 213948/414113 [00:47<00:43, 4643.66it/s]\u001b[A\n",
      " 52%|█████▏    | 214413/414113 [00:47<00:43, 4632.89it/s]\u001b[A\n",
      " 52%|█████▏    | 214885/414113 [00:48<00:42, 4657.53it/s]\u001b[A\n",
      " 52%|█████▏    | 215351/414113 [00:48<00:42, 4644.02it/s]\u001b[A\n",
      " 52%|█████▏    | 215818/414113 [00:48<00:42, 4650.58it/s]\u001b[A\n",
      " 52%|█████▏    | 216284/414113 [00:48<00:42, 4640.58it/s]\u001b[A\n",
      " 52%|█████▏    | 216752/414113 [00:48<00:42, 4650.29it/s]\u001b[A\n",
      " 52%|█████▏    | 217218/414113 [00:48<00:42, 4644.99it/s]\u001b[A\n",
      " 53%|█████▎    | 217700/414113 [00:48<00:41, 4694.62it/s]\u001b[A\n",
      " 53%|█████▎    | 218170/414113 [00:48<00:41, 4666.61it/s]\u001b[A\n",
      " 53%|█████▎    | 218646/414113 [00:48<00:41, 4691.71it/s]\u001b[A\n",
      " 53%|█████▎    | 219116/414113 [00:48<00:41, 4687.08it/s]\u001b[A\n",
      " 53%|█████▎    | 219593/414113 [00:49<00:41, 4709.78it/s]\u001b[A\n",
      " 53%|█████▎    | 220065/414113 [00:49<00:43, 4440.79it/s]\u001b[A\n",
      " 53%|█████▎    | 220539/414113 [00:49<00:42, 4524.94it/s]\u001b[A\n",
      " 53%|█████▎    | 220999/414113 [00:49<00:42, 4545.46it/s]\u001b[A\n",
      " 53%|█████▎    | 221463/414113 [00:49<00:42, 4571.44it/s]\u001b[A\n",
      " 54%|█████▎    | 221942/414113 [00:49<00:41, 4634.75it/s]\u001b[A\n",
      " 54%|█████▎    | 222407/414113 [00:49<00:41, 4636.52it/s]\u001b[A\n",
      " 54%|█████▍    | 222881/414113 [00:49<00:40, 4666.76it/s]\u001b[A\n",
      " 54%|█████▍    | 223349/414113 [00:49<00:41, 4649.28it/s]\u001b[A\n",
      " 54%|█████▍    | 223815/414113 [00:49<00:40, 4652.42it/s]\u001b[A\n",
      " 54%|█████▍    | 224287/414113 [00:50<00:40, 4671.62it/s]\u001b[A\n",
      " 54%|█████▍    | 224755/414113 [00:50<00:40, 4661.92it/s]\u001b[A\n",
      " 54%|█████▍    | 225230/414113 [00:50<00:40, 4687.12it/s]\u001b[A\n",
      " 55%|█████▍    | 225699/414113 [00:50<00:40, 4682.98it/s]\u001b[A\n",
      " 55%|█████▍    | 226168/414113 [00:50<00:40, 4674.04it/s]\u001b[A\n",
      " 55%|█████▍    | 226653/414113 [00:50<00:39, 4722.77it/s]\u001b[A\n",
      " 55%|█████▍    | 227126/414113 [00:50<00:41, 4553.19it/s]\u001b[A\n",
      " 55%|█████▍    | 227607/414113 [00:50<00:40, 4625.80it/s]\u001b[A\n",
      " 55%|█████▌    | 228071/414113 [00:50<00:40, 4620.14it/s]\u001b[A\n",
      " 55%|█████▌    | 228538/414113 [00:50<00:40, 4634.31it/s]\u001b[A\n",
      " 55%|█████▌    | 229015/414113 [00:51<00:39, 4672.74it/s]\u001b[A\n",
      " 55%|█████▌    | 229484/414113 [00:51<00:39, 4676.88it/s]\u001b[A\n",
      " 56%|█████▌    | 229953/414113 [00:51<00:39, 4657.89it/s]\u001b[A\n",
      " 56%|█████▌    | 230420/414113 [00:51<00:39, 4657.23it/s]\u001b[A\n",
      " 56%|█████▌    | 230890/414113 [00:51<00:39, 4669.37it/s]\u001b[A\n",
      " 56%|█████▌    | 231358/414113 [00:51<00:39, 4652.91it/s]\u001b[A\n",
      " 56%|█████▌    | 231824/414113 [00:51<00:39, 4636.44it/s]\u001b[A\n",
      " 56%|█████▌    | 232288/414113 [00:51<00:39, 4618.10it/s]\u001b[A\n",
      " 56%|█████▌    | 232750/414113 [00:51<00:39, 4545.88it/s]\u001b[A\n",
      " 56%|█████▋    | 233205/414113 [00:51<00:40, 4502.69it/s]\u001b[A\n",
      " 56%|█████▋    | 233662/414113 [00:52<00:39, 4521.42it/s]\u001b[A\n",
      " 57%|█████▋    | 234127/414113 [00:52<00:39, 4557.00it/s]\u001b[A\n",
      " 57%|█████▋    | 234590/414113 [00:52<00:39, 4577.11it/s]\u001b[A\n",
      " 57%|█████▋    | 235050/414113 [00:52<00:39, 4580.51it/s]\u001b[A\n",
      " 57%|█████▋    | 235509/414113 [00:52<00:39, 4564.05it/s]\u001b[A\n",
      " 57%|█████▋    | 235966/414113 [00:52<00:39, 4549.41it/s]\u001b[A\n",
      " 57%|█████▋    | 236422/414113 [00:52<00:39, 4539.06it/s]\u001b[A\n",
      " 57%|█████▋    | 236876/414113 [00:52<00:40, 4413.47it/s]\u001b[A\n",
      " 57%|█████▋    | 237333/414113 [00:52<00:39, 4458.60it/s]\u001b[A\n",
      " 57%|█████▋    | 237783/414113 [00:52<00:39, 4470.42it/s]\u001b[A\n",
      " 58%|█████▊    | 238245/414113 [00:53<00:38, 4512.39it/s]\u001b[A\n",
      " 58%|█████▊    | 238698/414113 [00:53<00:38, 4514.88it/s]\u001b[A\n",
      " 58%|█████▊    | 239156/414113 [00:53<00:38, 4532.99it/s]\u001b[A\n",
      " 58%|█████▊    | 239610/414113 [00:53<00:38, 4511.76it/s]\u001b[A\n",
      " 58%|█████▊    | 240069/414113 [00:53<00:38, 4533.45it/s]\u001b[A\n",
      " 58%|█████▊    | 240523/414113 [00:53<00:38, 4502.75it/s]\u001b[A\n",
      " 58%|█████▊    | 240978/414113 [00:53<00:38, 4516.28it/s]\u001b[A\n",
      " 58%|█████▊    | 241430/414113 [00:53<00:38, 4505.23it/s]\u001b[A\n",
      " 58%|█████▊    | 241881/414113 [00:53<00:38, 4487.62it/s]\u001b[A\n",
      " 59%|█████▊    | 242330/414113 [00:53<00:38, 4470.86it/s]\u001b[A\n",
      " 59%|█████▊    | 242778/414113 [00:54<00:38, 4465.39it/s]\u001b[A\n",
      " 59%|█████▊    | 243233/414113 [00:54<00:38, 4489.03it/s]\u001b[A\n",
      " 59%|█████▉    | 243682/414113 [00:54<00:38, 4457.13it/s]\u001b[A\n",
      " 59%|█████▉    | 244139/414113 [00:54<00:37, 4490.16it/s]\u001b[A\n",
      " 59%|█████▉    | 244594/414113 [00:54<00:37, 4505.29it/s]\u001b[A\n",
      " 59%|█████▉    | 245045/414113 [00:54<00:37, 4506.08it/s]\u001b[A\n",
      " 59%|█████▉    | 245501/414113 [00:54<00:37, 4519.77it/s]\u001b[A\n",
      " 59%|█████▉    | 245954/414113 [00:54<00:37, 4522.83it/s]\u001b[A\n",
      " 60%|█████▉    | 246412/414113 [00:54<00:36, 4539.63it/s]\u001b[A\n",
      " 60%|█████▉    | 246878/414113 [00:54<00:36, 4574.96it/s]\u001b[A\n",
      " 60%|█████▉    | 247336/414113 [00:55<00:36, 4574.47it/s]\u001b[A\n",
      " 60%|█████▉    | 247794/414113 [00:55<00:36, 4572.14it/s]\u001b[A\n",
      " 60%|█████▉    | 248252/414113 [00:55<00:36, 4488.52it/s]\u001b[A\n",
      " 60%|██████    | 248702/414113 [00:55<00:37, 4466.94it/s]\u001b[A\n",
      " 60%|██████    | 249149/414113 [00:55<00:36, 4464.44it/s]\u001b[A\n",
      " 60%|██████    | 249596/414113 [00:55<00:36, 4459.28it/s]\u001b[A\n",
      " 60%|██████    | 250048/414113 [00:55<00:36, 4477.27it/s]\u001b[A\n",
      " 60%|██████    | 250503/414113 [00:55<00:36, 4496.40it/s]\u001b[A\n",
      " 61%|██████    | 250953/414113 [00:55<00:36, 4484.36it/s]\u001b[A\n",
      " 61%|██████    | 251410/414113 [00:56<00:36, 4509.02it/s]\u001b[A\n",
      " 61%|██████    | 251876/414113 [00:56<00:35, 4550.79it/s]\u001b[A\n",
      " 61%|██████    | 252337/414113 [00:56<00:35, 4568.08it/s]\u001b[A\n",
      " 61%|██████    | 252798/414113 [00:56<00:35, 4580.24it/s]\u001b[A\n",
      " 61%|██████    | 253257/414113 [00:56<00:35, 4567.84it/s]\u001b[A\n",
      " 61%|██████▏   | 253714/414113 [00:56<00:35, 4561.71it/s]\u001b[A\n",
      " 61%|██████▏   | 254174/414113 [00:56<00:34, 4570.34it/s]\u001b[A\n",
      " 61%|██████▏   | 254632/414113 [00:56<00:34, 4563.92it/s]\u001b[A\n",
      " 62%|██████▏   | 255093/414113 [00:56<00:34, 4577.17it/s]\u001b[A\n",
      " 62%|██████▏   | 255551/414113 [00:56<00:34, 4576.22it/s]\u001b[A\n",
      " 62%|██████▏   | 256011/414113 [00:57<00:34, 4582.75it/s]\u001b[A\n",
      " 62%|██████▏   | 256476/414113 [00:57<00:34, 4600.48it/s]\u001b[A\n",
      " 62%|██████▏   | 256937/414113 [00:57<00:34, 4578.74it/s]\u001b[A\n",
      " 62%|██████▏   | 257395/414113 [00:57<00:35, 4400.75it/s]\u001b[A\n",
      " 62%|██████▏   | 257861/414113 [00:57<00:34, 4474.54it/s]\u001b[A\n",
      " 62%|██████▏   | 258310/414113 [00:57<00:34, 4452.50it/s]\u001b[A\n",
      " 62%|██████▏   | 258760/414113 [00:57<00:34, 4464.79it/s]\u001b[A\n",
      " 63%|██████▎   | 259208/414113 [00:57<00:34, 4467.80it/s]\u001b[A\n",
      " 63%|██████▎   | 259665/414113 [00:57<00:34, 4496.62it/s]\u001b[A\n",
      " 63%|██████▎   | 260128/414113 [00:57<00:33, 4534.63it/s]\u001b[A\n",
      " 63%|██████▎   | 260582/414113 [00:58<00:33, 4531.19it/s]\u001b[A\n",
      " 63%|██████▎   | 261046/414113 [00:58<00:33, 4561.27it/s]\u001b[A\n",
      " 63%|██████▎   | 261509/414113 [00:58<00:33, 4579.15it/s]\u001b[A\n",
      " 63%|██████▎   | 261968/414113 [00:58<00:33, 4580.38it/s]\u001b[A\n",
      " 63%|██████▎   | 262427/414113 [00:58<00:33, 4566.46it/s]\u001b[A\n",
      " 63%|██████▎   | 262884/414113 [00:58<00:33, 4557.88it/s]\u001b[A\n",
      " 64%|██████▎   | 263340/414113 [00:58<00:33, 4555.50it/s]\u001b[A\n",
      " 64%|██████▎   | 263796/414113 [00:58<00:33, 4516.18it/s]\u001b[A\n",
      " 64%|██████▍   | 264248/414113 [00:58<00:33, 4506.65it/s]\u001b[A\n",
      " 64%|██████▍   | 264699/414113 [00:58<00:33, 4479.62it/s]\u001b[A\n",
      " 64%|██████▍   | 265148/414113 [00:59<00:33, 4429.66it/s]\u001b[A\n",
      " 64%|██████▍   | 265592/414113 [00:59<00:33, 4407.22it/s]\u001b[A\n",
      " 64%|██████▍   | 266048/414113 [00:59<00:33, 4449.64it/s]\u001b[A\n",
      " 64%|██████▍   | 266500/414113 [00:59<00:33, 4470.44it/s]\u001b[A\n",
      " 64%|██████▍   | 266956/414113 [00:59<00:32, 4495.89it/s]\u001b[A\n",
      " 65%|██████▍   | 267413/414113 [00:59<00:32, 4515.85it/s]\u001b[A\n",
      " 65%|██████▍   | 267865/414113 [00:59<00:32, 4501.00it/s]\u001b[A\n",
      " 65%|██████▍   | 268316/414113 [00:59<00:32, 4480.57it/s]\u001b[A\n",
      " 65%|██████▍   | 268765/414113 [00:59<00:32, 4453.66it/s]\u001b[A\n",
      " 65%|██████▌   | 269213/414113 [00:59<00:32, 4461.09it/s]\u001b[A\n",
      " 65%|██████▌   | 269666/414113 [01:00<00:32, 4481.41it/s]\u001b[A\n",
      " 65%|██████▌   | 270115/414113 [01:00<00:32, 4483.13it/s]\u001b[A\n",
      " 65%|██████▌   | 270578/414113 [01:00<00:31, 4525.27it/s]\u001b[A\n",
      " 65%|██████▌   | 271038/414113 [01:00<00:31, 4544.70it/s]\u001b[A\n",
      " 66%|██████▌   | 271493/414113 [01:00<00:31, 4545.40it/s]\u001b[A\n",
      " 66%|██████▌   | 271953/414113 [01:00<00:31, 4561.60it/s]\u001b[A\n",
      " 66%|██████▌   | 272410/414113 [01:00<00:31, 4547.05it/s]\u001b[A\n",
      " 66%|██████▌   | 272868/414113 [01:00<00:31, 4555.95it/s]\u001b[A\n",
      " 66%|██████▌   | 273324/414113 [01:00<00:31, 4523.26it/s]\u001b[A\n",
      " 66%|██████▌   | 273779/414113 [01:00<00:30, 4528.49it/s]\u001b[A\n",
      " 66%|██████▌   | 274232/414113 [01:01<00:31, 4507.79it/s]\u001b[A\n",
      " 66%|██████▋   | 274698/414113 [01:01<00:30, 4550.66it/s]\u001b[A\n",
      " 66%|██████▋   | 275155/414113 [01:01<00:30, 4556.28it/s]\u001b[A\n",
      " 67%|██████▋   | 275616/414113 [01:01<00:30, 4570.19it/s]\u001b[A\n",
      " 67%|██████▋   | 276074/414113 [01:01<00:30, 4568.64it/s]\u001b[A\n",
      " 67%|██████▋   | 276533/414113 [01:01<00:30, 4573.88it/s]\u001b[A\n",
      " 67%|██████▋   | 276991/414113 [01:01<00:30, 4531.60it/s]\u001b[A\n",
      " 67%|██████▋   | 277446/414113 [01:01<00:30, 4535.98it/s]\u001b[A\n",
      " 67%|██████▋   | 277901/414113 [01:01<00:30, 4538.30it/s]\u001b[A\n",
      " 67%|██████▋   | 278358/414113 [01:01<00:29, 4546.80it/s]\u001b[A\n",
      " 67%|██████▋   | 278813/414113 [01:02<00:29, 4541.55it/s]\u001b[A\n",
      " 67%|██████▋   | 279272/414113 [01:02<00:29, 4554.95it/s]\u001b[A\n",
      " 68%|██████▊   | 279729/414113 [01:02<00:29, 4557.25it/s]\u001b[A\n",
      " 68%|██████▊   | 280187/414113 [01:02<00:29, 4563.80it/s]\u001b[A\n",
      " 68%|██████▊   | 280645/414113 [01:02<00:29, 4567.96it/s]\u001b[A\n",
      " 68%|██████▊   | 281103/414113 [01:02<00:29, 4571.43it/s]\u001b[A\n",
      " 68%|██████▊   | 281562/414113 [01:02<00:28, 4575.98it/s]\u001b[A\n",
      " 68%|██████▊   | 282020/414113 [01:02<00:28, 4575.11it/s]\u001b[A\n",
      " 68%|██████▊   | 282478/414113 [01:02<00:28, 4550.98it/s]\u001b[A\n",
      " 68%|██████▊   | 282934/414113 [01:02<00:28, 4543.83it/s]\u001b[A\n",
      " 68%|██████▊   | 283390/414113 [01:03<00:28, 4546.51it/s]\u001b[A\n",
      " 69%|██████▊   | 283855/414113 [01:03<00:28, 4576.19it/s]\u001b[A\n",
      " 69%|██████▊   | 284319/414113 [01:03<00:28, 4594.63it/s]\u001b[A\n",
      " 69%|██████▉   | 284789/414113 [01:03<00:27, 4624.85it/s]\u001b[A\n",
      " 69%|██████▉   | 285252/414113 [01:03<00:27, 4617.63it/s]\u001b[A\n",
      " 69%|██████▉   | 285719/414113 [01:03<00:27, 4629.59it/s]\u001b[A\n",
      " 69%|██████▉   | 286185/414113 [01:03<00:27, 4638.32it/s]\u001b[A\n",
      " 69%|██████▉   | 286649/414113 [01:03<00:27, 4593.69it/s]\u001b[A\n",
      " 69%|██████▉   | 287113/414113 [01:03<00:27, 4607.19it/s]\u001b[A\n",
      " 69%|██████▉   | 287576/414113 [01:03<00:27, 4613.58it/s]\u001b[A\n",
      " 70%|██████▉   | 288038/414113 [01:04<00:27, 4613.96it/s]\u001b[A\n",
      " 70%|██████▉   | 288502/414113 [01:04<00:27, 4620.22it/s]\u001b[A\n",
      " 70%|██████▉   | 288973/414113 [01:04<00:26, 4646.30it/s]\u001b[A\n",
      " 70%|██████▉   | 289438/414113 [01:04<00:26, 4632.85it/s]\u001b[A\n",
      " 70%|███████   | 289907/414113 [01:04<00:26, 4647.18it/s]\u001b[A\n",
      " 70%|███████   | 290372/414113 [01:04<00:26, 4643.23it/s]\u001b[A\n",
      " 70%|███████   | 290837/414113 [01:04<00:26, 4643.76it/s]\u001b[A\n",
      " 70%|███████   | 291302/414113 [01:04<00:26, 4609.77it/s]\u001b[A\n",
      " 70%|███████   | 291764/414113 [01:04<00:26, 4593.86it/s]\u001b[A\n",
      " 71%|███████   | 292234/414113 [01:04<00:26, 4623.72it/s]\u001b[A\n",
      " 71%|███████   | 292698/414113 [01:05<00:26, 4626.22it/s]\u001b[A\n",
      " 71%|███████   | 293171/414113 [01:05<00:25, 4655.01it/s]\u001b[A\n",
      " 71%|███████   | 293637/414113 [01:05<00:25, 4641.55it/s]\u001b[A\n",
      " 71%|███████   | 294104/414113 [01:05<00:25, 4648.21it/s]\u001b[A\n",
      " 71%|███████   | 294569/414113 [01:05<00:45, 2624.42it/s]\u001b[A\n",
      " 71%|███████   | 295027/414113 [01:05<00:39, 3008.91it/s]\u001b[A\n",
      " 71%|███████▏  | 295480/414113 [01:05<00:35, 3344.80it/s]\u001b[A\n",
      " 71%|███████▏  | 295929/414113 [01:06<00:32, 3620.22it/s]\u001b[A\n",
      " 72%|███████▏  | 296390/414113 [01:06<00:30, 3867.53it/s]\u001b[A\n",
      " 72%|███████▏  | 296852/414113 [01:06<00:28, 4064.38it/s]\u001b[A\n",
      " 72%|███████▏  | 297297/414113 [01:06<00:28, 4171.88it/s]\u001b[A\n",
      " 72%|███████▏  | 297749/414113 [01:06<00:27, 4269.19it/s]\u001b[A\n",
      " 72%|███████▏  | 298195/414113 [01:06<00:26, 4315.66it/s]\u001b[A\n",
      " 72%|███████▏  | 298659/414113 [01:06<00:26, 4406.74it/s]\u001b[A\n",
      " 72%|███████▏  | 299110/414113 [01:06<00:25, 4431.38it/s]\u001b[A\n",
      " 72%|███████▏  | 299562/414113 [01:06<00:25, 4456.79it/s]\u001b[A\n",
      " 72%|███████▏  | 300014/414113 [01:06<00:25, 4473.19it/s]\u001b[A\n",
      " 73%|███████▎  | 300465/414113 [01:07<00:25, 4458.68it/s]\u001b[A\n",
      " 73%|███████▎  | 300922/414113 [01:07<00:25, 4490.32it/s]\u001b[A\n",
      " 73%|███████▎  | 301381/414113 [01:07<00:24, 4517.33it/s]\u001b[A\n",
      " 73%|███████▎  | 301854/414113 [01:07<00:24, 4577.57it/s]\u001b[A\n",
      " 73%|███████▎  | 302313/414113 [01:07<00:24, 4563.12it/s]\u001b[A\n",
      " 73%|███████▎  | 302771/414113 [01:07<00:24, 4551.18it/s]\u001b[A\n",
      " 73%|███████▎  | 303227/414113 [01:07<00:24, 4551.35it/s]\u001b[A\n",
      " 73%|███████▎  | 303685/414113 [01:07<00:24, 4557.44it/s]\u001b[A\n",
      " 73%|███████▎  | 304142/414113 [01:07<00:24, 4523.83it/s]\u001b[A\n",
      " 74%|███████▎  | 304595/414113 [01:07<00:24, 4525.04it/s]\u001b[A\n",
      " 74%|███████▎  | 305048/414113 [01:08<00:24, 4512.16it/s]\u001b[A\n",
      " 74%|███████▍  | 305514/414113 [01:08<00:23, 4552.93it/s]\u001b[A\n",
      " 74%|███████▍  | 305970/414113 [01:08<00:23, 4537.27it/s]\u001b[A\n",
      " 74%|███████▍  | 306429/414113 [01:08<00:23, 4551.64it/s]\u001b[A\n",
      " 74%|███████▍  | 306885/414113 [01:08<00:23, 4554.04it/s]\u001b[A\n",
      " 74%|███████▍  | 307343/414113 [01:08<00:23, 4561.70it/s]\u001b[A\n",
      " 74%|███████▍  | 307803/414113 [01:08<00:23, 4571.59it/s]\u001b[A\n",
      " 74%|███████▍  | 308268/414113 [01:08<00:23, 4592.92it/s]\u001b[A\n",
      " 75%|███████▍  | 308728/414113 [01:08<00:23, 4578.06it/s]\u001b[A\n",
      " 75%|███████▍  | 309186/414113 [01:08<00:22, 4577.41it/s]\u001b[A\n",
      " 75%|███████▍  | 309647/414113 [01:09<00:22, 4585.93it/s]\u001b[A\n",
      " 75%|███████▍  | 310115/414113 [01:09<00:22, 4611.12it/s]\u001b[A\n",
      " 75%|███████▍  | 310577/414113 [01:09<00:22, 4563.08it/s]\u001b[A\n",
      " 75%|███████▌  | 311034/414113 [01:09<00:22, 4549.47it/s]\u001b[A\n",
      " 75%|███████▌  | 311490/414113 [01:09<00:22, 4549.39it/s]\u001b[A\n",
      " 75%|███████▌  | 311946/414113 [01:09<00:22, 4523.33it/s]\u001b[A\n",
      " 75%|███████▌  | 312407/414113 [01:09<00:22, 4547.68it/s]\u001b[A\n",
      " 76%|███████▌  | 312870/414113 [01:09<00:22, 4571.62it/s]\u001b[A\n",
      " 76%|███████▌  | 313328/414113 [01:09<00:22, 4560.95it/s]\u001b[A\n",
      " 76%|███████▌  | 313795/414113 [01:09<00:21, 4590.73it/s]\u001b[A\n",
      " 76%|███████▌  | 314255/414113 [01:10<00:21, 4581.26it/s]\u001b[A\n",
      " 76%|███████▌  | 314714/414113 [01:10<00:21, 4583.60it/s]\u001b[A\n",
      " 76%|███████▌  | 315173/414113 [01:10<00:21, 4562.98it/s]\u001b[A\n",
      " 76%|███████▌  | 315636/414113 [01:10<00:21, 4582.66it/s]\u001b[A\n",
      " 76%|███████▋  | 316095/414113 [01:10<00:21, 4580.53it/s]\u001b[A\n",
      " 76%|███████▋  | 316554/414113 [01:10<00:21, 4556.24it/s]\u001b[A\n",
      " 77%|███████▋  | 317010/414113 [01:10<00:21, 4530.67it/s]\u001b[A\n",
      " 77%|███████▋  | 317478/414113 [01:10<00:21, 4572.00it/s]\u001b[A\n",
      " 77%|███████▋  | 317936/414113 [01:10<00:21, 4551.85it/s]\u001b[A\n",
      " 77%|███████▋  | 318401/414113 [01:10<00:20, 4578.13it/s]\u001b[A\n",
      " 77%|███████▋  | 318859/414113 [01:11<00:20, 4572.41it/s]\u001b[A\n",
      " 77%|███████▋  | 319317/414113 [01:11<00:20, 4533.35it/s]\u001b[A\n",
      " 77%|███████▋  | 319771/414113 [01:11<00:21, 4459.92it/s]\u001b[A\n",
      " 77%|███████▋  | 320241/414113 [01:11<00:20, 4528.61it/s]\u001b[A\n",
      " 77%|███████▋  | 320696/414113 [01:11<00:20, 4534.83it/s]\u001b[A\n",
      " 78%|███████▊  | 321161/414113 [01:11<00:20, 4566.40it/s]\u001b[A\n",
      " 78%|███████▊  | 321622/414113 [01:11<00:20, 4576.46it/s]\u001b[A\n",
      " 78%|███████▊  | 322086/414113 [01:11<00:20, 4594.39it/s]\u001b[A\n",
      " 78%|███████▊  | 322546/414113 [01:11<00:20, 4559.95it/s]\u001b[A\n",
      " 78%|███████▊  | 323015/414113 [01:11<00:19, 4596.90it/s]\u001b[A\n",
      " 78%|███████▊  | 323480/414113 [01:12<00:19, 4611.84it/s]\u001b[A\n",
      " 78%|███████▊  | 323942/414113 [01:12<00:19, 4612.46it/s]\u001b[A\n",
      " 78%|███████▊  | 324404/414113 [01:12<00:19, 4593.69it/s]\u001b[A\n",
      " 78%|███████▊  | 324868/414113 [01:12<00:19, 4607.37it/s]\u001b[A\n",
      " 79%|███████▊  | 325329/414113 [01:12<00:19, 4572.80it/s]\u001b[A\n",
      " 79%|███████▊  | 325787/414113 [01:12<00:19, 4572.94it/s]\u001b[A\n",
      " 79%|███████▉  | 326251/414113 [01:12<00:19, 4592.59it/s]\u001b[A\n",
      " 79%|███████▉  | 326714/414113 [01:12<00:18, 4602.11it/s]\u001b[A\n",
      " 79%|███████▉  | 327178/414113 [01:12<00:18, 4611.65it/s]\u001b[A\n",
      " 79%|███████▉  | 327640/414113 [01:12<00:18, 4592.73it/s]\u001b[A\n",
      " 79%|███████▉  | 328100/414113 [01:13<00:18, 4579.93it/s]\u001b[A\n",
      " 79%|███████▉  | 328559/414113 [01:13<00:18, 4557.86it/s]\u001b[A\n",
      " 79%|███████▉  | 329015/414113 [01:13<00:18, 4558.33it/s]\u001b[A\n",
      " 80%|███████▉  | 329471/414113 [01:13<00:18, 4500.42it/s]\u001b[A\n",
      " 80%|███████▉  | 329925/414113 [01:13<00:18, 4511.15it/s]\u001b[A\n",
      " 80%|███████▉  | 330377/414113 [01:13<00:18, 4463.78it/s]\u001b[A\n",
      " 80%|███████▉  | 330824/414113 [01:13<00:18, 4432.49it/s]\u001b[A\n",
      " 80%|███████▉  | 331268/414113 [01:13<00:19, 4306.32it/s]\u001b[A\n",
      " 80%|████████  | 331726/414113 [01:13<00:18, 4383.87it/s]\u001b[A\n",
      " 80%|████████  | 332190/414113 [01:14<00:18, 4454.90it/s]\u001b[A\n",
      " 80%|████████  | 332643/414113 [01:14<00:18, 4473.96it/s]\u001b[A\n",
      " 80%|████████  | 333098/414113 [01:14<00:18, 4494.17it/s]\u001b[A\n",
      " 81%|████████  | 333562/414113 [01:14<00:17, 4535.95it/s]\u001b[A\n",
      " 81%|████████  | 334017/414113 [01:14<00:17, 4517.90it/s]\u001b[A\n",
      " 81%|████████  | 334470/414113 [01:14<00:17, 4486.37it/s]\u001b[A\n",
      " 81%|████████  | 334924/414113 [01:14<00:17, 4501.81it/s]\u001b[A\n",
      " 81%|████████  | 335375/414113 [01:14<00:17, 4491.67it/s]\u001b[A\n",
      " 81%|████████  | 335825/414113 [01:14<00:17, 4439.11it/s]\u001b[A\n",
      " 81%|████████  | 336282/414113 [01:14<00:17, 4476.35it/s]\u001b[A\n",
      " 81%|████████▏ | 336737/414113 [01:15<00:17, 4497.70it/s]\u001b[A\n",
      " 81%|████████▏ | 337187/414113 [01:15<00:17, 4496.40it/s]\u001b[A\n",
      " 82%|████████▏ | 337645/414113 [01:15<00:16, 4520.46it/s]\u001b[A\n",
      " 82%|████████▏ | 338098/414113 [01:15<00:17, 4464.55it/s]\u001b[A\n",
      " 82%|████████▏ | 338552/414113 [01:15<00:16, 4485.00it/s]\u001b[A\n",
      " 82%|████████▏ | 339001/414113 [01:15<00:19, 3854.91it/s]\u001b[A\n",
      " 82%|████████▏ | 339448/414113 [01:15<00:18, 4020.29it/s]\u001b[A\n",
      " 82%|████████▏ | 339880/414113 [01:15<00:18, 4105.73it/s]\u001b[A\n",
      " 82%|████████▏ | 340336/414113 [01:15<00:17, 4231.24it/s]\u001b[A\n",
      " 82%|████████▏ | 340797/414113 [01:15<00:16, 4336.33it/s]\u001b[A\n",
      " 82%|████████▏ | 341240/414113 [01:16<00:16, 4361.89it/s]\u001b[A\n",
      " 83%|████████▎ | 341700/414113 [01:16<00:16, 4430.63it/s]\u001b[A\n",
      " 83%|████████▎ | 342149/414113 [01:16<00:16, 4447.16it/s]\u001b[A\n",
      " 83%|████████▎ | 342615/414113 [01:16<00:15, 4508.01it/s]\u001b[A\n",
      " 83%|████████▎ | 343068/414113 [01:16<00:15, 4477.81it/s]\u001b[A\n",
      " 83%|████████▎ | 343533/414113 [01:16<00:15, 4525.70it/s]\u001b[A\n",
      " 83%|████████▎ | 343991/414113 [01:16<00:15, 4540.51it/s]\u001b[A\n",
      " 83%|████████▎ | 344446/414113 [01:16<00:15, 4498.33it/s]\u001b[A\n",
      " 83%|████████▎ | 344902/414113 [01:16<00:15, 4514.00it/s]\u001b[A\n",
      " 83%|████████▎ | 345354/414113 [01:16<00:15, 4496.92it/s]\u001b[A\n",
      " 84%|████████▎ | 345814/414113 [01:17<00:15, 4525.05it/s]\u001b[A\n",
      " 84%|████████▎ | 346267/414113 [01:17<00:15, 4521.16it/s]\u001b[A\n",
      " 84%|████████▎ | 346720/414113 [01:17<00:15, 4426.01it/s]\u001b[A\n",
      " 84%|████████▍ | 347175/414113 [01:17<00:15, 4461.16it/s]\u001b[A\n",
      " 84%|████████▍ | 347630/414113 [01:17<00:14, 4486.53it/s]\u001b[A\n",
      " 84%|████████▍ | 348080/414113 [01:17<00:14, 4485.34it/s]\u001b[A\n",
      " 84%|████████▍ | 348531/414113 [01:17<00:14, 4491.45it/s]\u001b[A\n",
      " 84%|████████▍ | 348986/414113 [01:17<00:14, 4506.17it/s]\u001b[A\n",
      " 84%|████████▍ | 349444/414113 [01:17<00:14, 4525.66it/s]\u001b[A\n",
      " 84%|████████▍ | 349904/414113 [01:17<00:14, 4547.52it/s]\u001b[A\n",
      " 85%|████████▍ | 350368/414113 [01:18<00:13, 4572.69it/s]\u001b[A\n",
      " 85%|████████▍ | 350826/414113 [01:18<00:13, 4568.62it/s]\u001b[A\n",
      " 85%|████████▍ | 351295/414113 [01:18<00:13, 4603.22it/s]\u001b[A\n",
      " 85%|████████▍ | 351756/414113 [01:18<00:13, 4589.85it/s]\u001b[A\n",
      " 85%|████████▌ | 352216/414113 [01:18<00:13, 4585.45it/s]\u001b[A\n",
      " 85%|████████▌ | 352675/414113 [01:18<00:13, 4538.15it/s]\u001b[A\n",
      " 85%|████████▌ | 353130/414113 [01:18<00:13, 4537.48it/s]\u001b[A\n",
      " 85%|████████▌ | 353593/414113 [01:18<00:13, 4563.75it/s]\u001b[A\n",
      " 85%|████████▌ | 354050/414113 [01:18<00:13, 4547.99it/s]\u001b[A\n",
      " 86%|████████▌ | 354505/414113 [01:18<00:13, 4541.28it/s]\u001b[A\n",
      " 86%|████████▌ | 354969/414113 [01:19<00:12, 4568.92it/s]\u001b[A\n",
      " 86%|████████▌ | 355429/414113 [01:19<00:12, 4577.49it/s]\u001b[A\n",
      " 86%|████████▌ | 355888/414113 [01:19<00:12, 4578.74it/s]\u001b[A\n",
      " 86%|████████▌ | 356346/414113 [01:19<00:12, 4578.43it/s]\u001b[A\n",
      " 86%|████████▌ | 356804/414113 [01:19<00:12, 4578.41it/s]\u001b[A\n",
      " 86%|████████▋ | 357262/414113 [01:19<00:12, 4544.53it/s]\u001b[A\n",
      " 86%|████████▋ | 357727/414113 [01:19<00:12, 4575.46it/s]\u001b[A\n",
      " 86%|████████▋ | 358185/414113 [01:19<00:12, 4553.97it/s]\u001b[A\n",
      " 87%|████████▋ | 358653/414113 [01:19<00:12, 4589.83it/s]\u001b[A\n",
      " 87%|████████▋ | 359117/414113 [01:20<00:11, 4602.54it/s]\u001b[A\n",
      " 87%|████████▋ | 359578/414113 [01:20<00:11, 4577.11it/s]\u001b[A\n",
      " 87%|████████▋ | 360042/414113 [01:20<00:11, 4594.42it/s]\u001b[A\n",
      " 87%|████████▋ | 360502/414113 [01:20<00:11, 4594.28it/s]\u001b[A\n",
      " 87%|████████▋ | 360962/414113 [01:20<00:11, 4539.47it/s]\u001b[A\n",
      " 87%|████████▋ | 361422/414113 [01:20<00:11, 4555.77it/s]\u001b[A\n",
      " 87%|████████▋ | 361878/414113 [01:20<00:11, 4548.13it/s]\u001b[A\n",
      " 87%|████████▋ | 362333/414113 [01:20<00:11, 4529.17it/s]\u001b[A\n",
      " 88%|████████▊ | 362788/414113 [01:20<00:11, 4534.01it/s]\u001b[A\n",
      " 88%|████████▊ | 363242/414113 [01:20<00:11, 4522.17it/s]\u001b[A\n",
      " 88%|████████▊ | 363695/414113 [01:21<00:11, 4505.77it/s]\u001b[A\n",
      " 88%|████████▊ | 364149/414113 [01:21<00:11, 4515.37it/s]\u001b[A\n",
      " 88%|████████▊ | 364604/414113 [01:21<00:10, 4525.49it/s]\u001b[A\n",
      " 88%|████████▊ | 365063/414113 [01:21<00:10, 4543.55it/s]\u001b[A\n",
      " 88%|████████▊ | 365520/414113 [01:21<00:10, 4551.42it/s]\u001b[A\n",
      " 88%|████████▊ | 365983/414113 [01:21<00:10, 4572.21it/s]\u001b[A\n",
      " 88%|████████▊ | 366443/414113 [01:21<00:10, 4580.29it/s]\u001b[A\n",
      " 89%|████████▊ | 366902/414113 [01:21<00:10, 4564.38it/s]\u001b[A\n",
      " 89%|████████▊ | 367359/414113 [01:21<00:10, 4535.54it/s]\u001b[A\n",
      " 89%|████████▉ | 367813/414113 [01:21<00:10, 4518.79it/s]\u001b[A\n",
      " 89%|████████▉ | 368265/414113 [01:22<00:10, 4499.74it/s]\u001b[A\n",
      " 89%|████████▉ | 368719/414113 [01:22<00:10, 4509.24it/s]\u001b[A\n",
      " 89%|████████▉ | 369170/414113 [01:22<00:09, 4508.12it/s]\u001b[A\n",
      " 89%|████████▉ | 369621/414113 [01:22<00:09, 4500.42it/s]\u001b[A\n",
      " 89%|████████▉ | 370072/414113 [01:22<00:09, 4495.77it/s]\u001b[A\n",
      " 89%|████████▉ | 370522/414113 [01:22<00:09, 4464.95it/s]\u001b[A\n",
      " 90%|████████▉ | 370969/414113 [01:22<00:09, 4456.48it/s]\u001b[A\n",
      " 90%|████████▉ | 371415/414113 [01:22<00:09, 4436.68it/s]\u001b[A\n",
      " 90%|████████▉ | 371860/414113 [01:22<00:09, 4439.08it/s]\u001b[A\n",
      " 90%|████████▉ | 372310/414113 [01:22<00:09, 4456.73it/s]\u001b[A\n",
      " 90%|█████████ | 372756/414113 [01:23<00:09, 4451.30it/s]\u001b[A\n",
      " 90%|█████████ | 373202/414113 [01:23<00:09, 4263.37it/s]\u001b[A\n",
      " 90%|█████████ | 373651/414113 [01:23<00:09, 4328.28it/s]\u001b[A\n",
      " 90%|█████████ | 374116/414113 [01:23<00:09, 4417.96it/s]\u001b[A\n",
      " 90%|█████████ | 374569/414113 [01:23<00:08, 4450.16it/s]\u001b[A\n",
      " 91%|█████████ | 375018/414113 [01:23<00:08, 4460.43it/s]\u001b[A\n",
      " 91%|█████████ | 375469/414113 [01:23<00:08, 4473.69it/s]\u001b[A\n",
      " 91%|█████████ | 375932/414113 [01:23<00:08, 4518.82it/s]\u001b[A\n",
      " 91%|█████████ | 376385/414113 [01:23<00:08, 4508.34it/s]\u001b[A\n",
      " 91%|█████████ | 376837/414113 [01:23<00:08, 4506.79it/s]\u001b[A\n",
      " 91%|█████████ | 377288/414113 [01:24<00:08, 4485.52it/s]\u001b[A\n",
      " 91%|█████████ | 377743/414113 [01:24<00:08, 4502.91it/s]\u001b[A\n",
      " 91%|█████████▏| 378196/414113 [01:24<00:07, 4510.90it/s]\u001b[A\n",
      " 91%|█████████▏| 378653/414113 [01:24<00:07, 4528.42it/s]\u001b[A\n",
      " 92%|█████████▏| 379106/414113 [01:24<00:07, 4523.98it/s]\u001b[A\n",
      " 92%|█████████▏| 379559/414113 [01:24<00:07, 4471.37it/s]\u001b[A\n",
      " 92%|█████████▏| 380016/414113 [01:24<00:07, 4500.30it/s]\u001b[A\n",
      " 92%|█████████▏| 380467/414113 [01:24<00:07, 4478.80it/s]\u001b[A\n",
      " 92%|█████████▏| 380917/414113 [01:24<00:07, 4484.58it/s]\u001b[A\n",
      " 92%|█████████▏| 381378/414113 [01:24<00:07, 4518.20it/s]\u001b[A\n",
      " 92%|█████████▏| 381830/414113 [01:25<00:07, 4507.13it/s]\u001b[A\n",
      " 92%|█████████▏| 382281/414113 [01:25<00:07, 4397.65it/s]\u001b[A\n",
      " 92%|█████████▏| 382734/414113 [01:25<00:07, 4436.00it/s]\u001b[A\n",
      " 93%|█████████▎| 383192/414113 [01:25<00:06, 4477.90it/s]\u001b[A\n",
      " 93%|█████████▎| 383655/414113 [01:25<00:06, 4520.02it/s]\u001b[A\n",
      " 93%|█████████▎| 384108/414113 [01:25<00:06, 4511.64it/s]\u001b[A\n",
      " 93%|█████████▎| 384563/414113 [01:25<00:06, 4521.54it/s]\u001b[A\n",
      " 93%|█████████▎| 385016/414113 [01:25<00:06, 4521.93it/s]\u001b[A\n",
      " 93%|█████████▎| 385469/414113 [01:25<00:06, 4503.92it/s]\u001b[A\n",
      " 93%|█████████▎| 385920/414113 [01:25<00:06, 4472.96it/s]\u001b[A\n",
      " 93%|█████████▎| 386378/414113 [01:26<00:06, 4503.01it/s]\u001b[A\n",
      " 93%|█████████▎| 386837/414113 [01:26<00:06, 4528.62it/s]\u001b[A\n",
      " 94%|█████████▎| 387296/414113 [01:26<00:05, 4546.75it/s]\u001b[A\n",
      " 94%|█████████▎| 387754/414113 [01:26<00:05, 4555.21it/s]\u001b[A\n",
      " 94%|█████████▎| 388210/414113 [01:26<00:05, 4500.94it/s]\u001b[A\n",
      " 94%|█████████▍| 388661/414113 [01:26<00:05, 4480.57it/s]\u001b[A\n",
      " 94%|█████████▍| 389119/414113 [01:26<00:05, 4509.21it/s]\u001b[A\n",
      " 94%|█████████▍| 389577/414113 [01:26<00:05, 4528.73it/s]\u001b[A\n",
      " 94%|█████████▍| 390031/414113 [01:26<00:05, 4489.25it/s]\u001b[A\n",
      " 94%|█████████▍| 390495/414113 [01:26<00:05, 4530.59it/s]\u001b[A\n",
      " 94%|█████████▍| 390949/414113 [01:27<00:05, 4484.70it/s]\u001b[A\n",
      " 95%|█████████▍| 391412/414113 [01:27<00:05, 4525.62it/s]\u001b[A\n",
      " 95%|█████████▍| 391867/414113 [01:27<00:04, 4531.62it/s]\u001b[A\n",
      " 95%|█████████▍| 392321/414113 [01:27<00:04, 4413.63it/s]\u001b[A\n",
      " 95%|█████████▍| 392774/414113 [01:27<00:04, 4447.59it/s]\u001b[A\n",
      " 95%|█████████▍| 393222/414113 [01:27<00:04, 4453.42it/s]\u001b[A\n",
      " 95%|█████████▌| 393679/414113 [01:27<00:04, 4486.35it/s]\u001b[A\n",
      " 95%|█████████▌| 394129/414113 [01:27<00:04, 4481.22it/s]\u001b[A\n",
      " 95%|█████████▌| 394590/414113 [01:27<00:04, 4516.13it/s]\u001b[A\n",
      " 95%|█████████▌| 395042/414113 [01:27<00:04, 4474.39it/s]\u001b[A\n",
      " 96%|█████████▌| 395493/414113 [01:28<00:04, 4484.76it/s]\u001b[A\n",
      " 96%|█████████▌| 395942/414113 [01:28<00:04, 4461.62it/s]\u001b[A\n",
      " 96%|█████████▌| 396394/414113 [01:28<00:03, 4478.64it/s]\u001b[A\n",
      " 96%|█████████▌| 396845/414113 [01:28<00:03, 4485.90it/s]\u001b[A\n",
      " 96%|█████████▌| 397304/414113 [01:28<00:03, 4515.97it/s]\u001b[A\n",
      " 96%|█████████▌| 397761/414113 [01:28<00:03, 4530.92it/s]\u001b[A\n",
      " 96%|█████████▌| 398219/414113 [01:28<00:03, 4543.34it/s]\u001b[A\n",
      " 96%|█████████▋| 398674/414113 [01:28<00:03, 4502.17it/s]\u001b[A\n",
      " 96%|█████████▋| 399129/414113 [01:28<00:03, 4514.97it/s]\u001b[A\n",
      " 96%|█████████▋| 399581/414113 [01:28<00:03, 4514.84it/s]\u001b[A\n",
      " 97%|█████████▋| 400040/414113 [01:29<00:03, 4535.06it/s]\u001b[A\n",
      " 97%|█████████▋| 400494/414113 [01:29<00:03, 4536.44it/s]\u001b[A\n",
      " 97%|█████████▋| 400953/414113 [01:29<00:02, 4552.28it/s]\u001b[A\n",
      " 97%|█████████▋| 401409/414113 [01:29<00:02, 4546.81it/s]\u001b[A\n",
      " 97%|█████████▋| 401864/414113 [01:29<00:02, 4547.71it/s]\u001b[A\n",
      " 97%|█████████▋| 402322/414113 [01:29<00:02, 4556.05it/s]\u001b[A\n",
      " 97%|█████████▋| 402778/414113 [01:29<00:02, 4538.44it/s]\u001b[A\n",
      " 97%|█████████▋| 403232/414113 [01:29<00:02, 4522.30it/s]\u001b[A\n",
      " 97%|█████████▋| 403685/414113 [01:29<00:02, 4491.02it/s]\u001b[A\n",
      " 98%|█████████▊| 404152/414113 [01:30<00:02, 4542.91it/s]\u001b[A\n",
      " 98%|█████████▊| 404613/414113 [01:30<00:02, 4561.29it/s]\u001b[A\n",
      " 98%|█████████▊| 405070/414113 [01:30<00:01, 4541.12it/s]\u001b[A\n",
      " 98%|█████████▊| 405527/414113 [01:30<00:01, 4548.72it/s]\u001b[A\n",
      " 98%|█████████▊| 405982/414113 [01:30<00:01, 4532.10it/s]\u001b[A\n",
      " 98%|█████████▊| 406440/414113 [01:30<00:01, 4543.44it/s]\u001b[A\n",
      " 98%|█████████▊| 406907/414113 [01:30<00:01, 4579.47it/s]\u001b[A\n",
      " 98%|█████████▊| 407366/414113 [01:30<00:01, 4567.63it/s]\u001b[A\n",
      " 98%|█████████▊| 407827/414113 [01:30<00:01, 4577.73it/s]\u001b[A\n",
      " 99%|█████████▊| 408287/414113 [01:30<00:01, 4582.44it/s]\u001b[A\n",
      " 99%|█████████▊| 408754/414113 [01:31<00:01, 4606.93it/s]\u001b[A\n",
      " 99%|█████████▉| 409215/414113 [01:31<00:01, 4582.32it/s]\u001b[A\n",
      " 99%|█████████▉| 409679/414113 [01:31<00:00, 4599.16it/s]\u001b[A\n",
      " 99%|█████████▉| 410139/414113 [01:31<00:00, 4445.11it/s]\u001b[A\n",
      " 99%|█████████▉| 410605/414113 [01:31<00:00, 4505.20it/s]\u001b[A\n",
      " 99%|█████████▉| 411057/414113 [01:31<00:00, 4452.75it/s]\u001b[A\n",
      " 99%|█████████▉| 411522/414113 [01:31<00:00, 4509.91it/s]\u001b[A\n",
      " 99%|█████████▉| 411974/414113 [01:31<00:00, 4469.89it/s]\u001b[A\n",
      "100%|█████████▉| 412434/414113 [01:31<00:00, 4505.86it/s]\u001b[A\n",
      "100%|█████████▉| 412892/414113 [01:31<00:00, 4526.51it/s]\u001b[A\n",
      "100%|█████████▉| 413360/414113 [01:32<00:00, 4569.39it/s]\u001b[A\n",
      "100%|█████████▉| 413818/414113 [01:32<00:00, 4548.74it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:32<00:00, 4491.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=1.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "import torch.optim\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters())+list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 4.4216, Perplexity: 83.2320\n",
      "Epoch [1/3], Step [200/6471], Loss: 4.1116, Perplexity: 61.04519\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.5112, Perplexity: 33.48914\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.8822, Perplexity: 48.5329\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.6172, Perplexity: 37.23389\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.5526, Perplexity: 34.9036\n",
      "Epoch [1/3], Step [700/6471], Loss: 3.3339, Perplexity: 28.0484\n",
      "Epoch [1/3], Step [800/6471], Loss: 2.9673, Perplexity: 19.4393\n",
      "Epoch [1/3], Step [900/6471], Loss: 3.3278, Perplexity: 27.8771\n",
      "Epoch [1/3], Step [1000/6471], Loss: 3.2000, Perplexity: 24.5318\n",
      "Epoch [1/3], Step [1100/6471], Loss: 3.0307, Perplexity: 20.7112\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.8793, Perplexity: 17.8026\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.9192, Perplexity: 18.5271\n",
      "Epoch [1/3], Step [1400/6471], Loss: 3.3452, Perplexity: 28.3654\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.8609, Perplexity: 17.4770\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.6110, Perplexity: 13.6125\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.8855, Perplexity: 17.9128\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.8133, Perplexity: 16.6654\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.7456, Perplexity: 15.5742\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.6930, Perplexity: 14.7766\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.5436, Perplexity: 12.7253\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.6851, Perplexity: 14.6596\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.7510, Perplexity: 15.6584\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.4699, Perplexity: 11.8210\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.6521, Perplexity: 14.1836\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.5681, Perplexity: 13.0415\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.6264, Perplexity: 13.8244\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.4046, Perplexity: 11.0735\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.4954, Perplexity: 12.1270\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.3746, Perplexity: 10.7467\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.2149, Perplexity: 9.16038\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.3460, Perplexity: 10.4438\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.8460, Perplexity: 17.2192\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.3496, Perplexity: 10.4816\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.4609, Perplexity: 11.7150\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.2630, Perplexity: 9.61212\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.4339, Perplexity: 11.4034\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.4923, Perplexity: 12.0891\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.5452, Perplexity: 12.74546\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.4474, Perplexity: 11.5585\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.2834, Perplexity: 9.809520\n",
      "Epoch [1/3], Step [4200/6471], Loss: 2.4223, Perplexity: 11.2722\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.5470, Perplexity: 12.7692\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.2301, Perplexity: 9.30128\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.2834, Perplexity: 9.80978\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.1723, Perplexity: 8.77828\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.3400, Perplexity: 10.3809\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.0637, Perplexity: 7.87483\n",
      "Epoch [1/3], Step [4900/6471], Loss: 2.9043, Perplexity: 18.2526\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.2191, Perplexity: 9.19950\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.1558, Perplexity: 8.63466\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.2396, Perplexity: 9.38955\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.3519, Perplexity: 10.5050\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.1992, Perplexity: 9.01809\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.1648, Perplexity: 8.71308\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.3772, Perplexity: 10.7751\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.1950, Perplexity: 8.98010\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.3161, Perplexity: 10.1364\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.1369, Perplexity: 8.47353\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.3065, Perplexity: 10.0389\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.2845, Perplexity: 9.82051\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.6753, Perplexity: 14.5169\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.2392, Perplexity: 9.38627\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.0198, Perplexity: 7.53686\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.0273, Perplexity: 7.593358\n",
      "Epoch [2/3], Step [200/6471], Loss: 2.1034, Perplexity: 8.19370\n",
      "Epoch [2/3], Step [300/6471], Loss: 2.2040, Perplexity: 9.060977\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.0515, Perplexity: 7.77935\n",
      "Epoch [2/3], Step [500/6471], Loss: 2.1178, Perplexity: 8.31252\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.1463, Perplexity: 8.55366\n",
      "Epoch [2/3], Step [700/6471], Loss: 2.3006, Perplexity: 9.98009\n",
      "Epoch [2/3], Step [800/6471], Loss: 2.1753, Perplexity: 8.80469\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.1700, Perplexity: 8.75796\n",
      "Epoch [2/3], Step [1000/6471], Loss: 2.5143, Perplexity: 12.3584\n",
      "Epoch [2/3], Step [1100/6471], Loss: 1.9403, Perplexity: 6.96120\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.0934, Perplexity: 8.11254\n",
      "Epoch [2/3], Step [1300/6471], Loss: 2.0324, Perplexity: 7.63274\n",
      "Epoch [2/3], Step [1400/6471], Loss: 2.1093, Perplexity: 8.24253\n",
      "Epoch [2/3], Step [1500/6471], Loss: 2.4494, Perplexity: 11.5816\n",
      "Epoch [2/3], Step [1600/6471], Loss: 2.0524, Perplexity: 7.78665\n",
      "Epoch [2/3], Step [1700/6471], Loss: 2.1793, Perplexity: 8.84026\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.2781, Perplexity: 9.75793\n",
      "Epoch [2/3], Step [1900/6471], Loss: 2.9638, Perplexity: 19.3720\n",
      "Epoch [2/3], Step [2000/6471], Loss: 1.8262, Perplexity: 6.21040\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.9223, Perplexity: 18.5840\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.2136, Perplexity: 9.14849\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.2182, Perplexity: 9.19036\n",
      "Epoch [2/3], Step [2400/6471], Loss: 2.4732, Perplexity: 11.8603\n",
      "Epoch [2/3], Step [2500/6471], Loss: 2.0963, Perplexity: 8.13593\n",
      "Epoch [2/3], Step [2600/6471], Loss: 2.1873, Perplexity: 8.91110\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.0379, Perplexity: 7.67478\n",
      "Epoch [2/3], Step [2800/6471], Loss: 2.1396, Perplexity: 8.49584\n",
      "Epoch [2/3], Step [2900/6471], Loss: 2.0280, Perplexity: 7.59916\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.1512, Perplexity: 8.59516\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.2104, Perplexity: 9.11957\n",
      "Epoch [2/3], Step [3200/6471], Loss: 2.1093, Perplexity: 8.24233\n",
      "Epoch [2/3], Step [3300/6471], Loss: 2.3102, Perplexity: 10.0768\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.0117, Perplexity: 7.47597\n",
      "Epoch [2/3], Step [3500/6471], Loss: 1.8585, Perplexity: 6.41429\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.0646, Perplexity: 7.88230\n",
      "Epoch [2/3], Step [3700/6471], Loss: 2.1575, Perplexity: 8.64954\n",
      "Epoch [2/3], Step [3800/6471], Loss: 2.1763, Perplexity: 8.81342\n",
      "Epoch [2/3], Step [3900/6471], Loss: 2.1391, Perplexity: 8.49172\n",
      "Epoch [2/3], Step [4000/6471], Loss: 2.1886, Perplexity: 8.92257\n",
      "Epoch [2/3], Step [4100/6471], Loss: 2.0137, Perplexity: 7.49127\n",
      "Epoch [2/3], Step [4200/6471], Loss: 2.1090, Perplexity: 8.23971\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.2469, Perplexity: 9.458764\n",
      "Epoch [2/3], Step [4400/6471], Loss: 2.0685, Perplexity: 7.91277\n",
      "Epoch [2/3], Step [4500/6471], Loss: 2.0608, Perplexity: 7.85212\n",
      "Epoch [2/3], Step [4600/6471], Loss: 2.0040, Perplexity: 7.41837\n",
      "Epoch [2/3], Step [4700/6471], Loss: 1.9786, Perplexity: 7.23277\n",
      "Epoch [2/3], Step [4800/6471], Loss: 2.0364, Perplexity: 7.66323\n",
      "Epoch [2/3], Step [4900/6471], Loss: 1.9958, Perplexity: 7.35789\n",
      "Epoch [2/3], Step [5000/6471], Loss: 1.9020, Perplexity: 6.69940\n",
      "Epoch [2/3], Step [5100/6471], Loss: 2.1707, Perplexity: 8.76440\n",
      "Epoch [2/3], Step [5200/6471], Loss: 2.0528, Perplexity: 7.78946\n",
      "Epoch [2/3], Step [5300/6471], Loss: 2.1077, Perplexity: 8.22915\n",
      "Epoch [2/3], Step [5400/6471], Loss: 2.0073, Perplexity: 7.44339\n",
      "Epoch [2/3], Step [5500/6471], Loss: 1.9623, Perplexity: 7.11587\n",
      "Epoch [2/3], Step [5600/6471], Loss: 2.1496, Perplexity: 8.58179\n",
      "Epoch [2/3], Step [5700/6471], Loss: 2.0005, Perplexity: 7.39288\n",
      "Epoch [2/3], Step [5800/6471], Loss: 2.1088, Perplexity: 8.23824\n",
      "Epoch [2/3], Step [5900/6471], Loss: 2.0390, Perplexity: 7.68295\n",
      "Epoch [2/3], Step [6000/6471], Loss: 1.9117, Perplexity: 6.76486\n",
      "Epoch [2/3], Step [6100/6471], Loss: 2.2685, Perplexity: 9.66532\n",
      "Epoch [2/3], Step [6200/6471], Loss: 1.9860, Perplexity: 7.28627\n",
      "Epoch [2/3], Step [6300/6471], Loss: 2.0196, Perplexity: 7.53561\n",
      "Epoch [2/3], Step [6400/6471], Loss: 2.1511, Perplexity: 8.59440\n",
      "Epoch [3/3], Step [100/6471], Loss: 2.1720, Perplexity: 8.775740\n",
      "Epoch [3/3], Step [200/6471], Loss: 2.0557, Perplexity: 7.81196\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.1011, Perplexity: 8.17489\n",
      "Epoch [3/3], Step [400/6471], Loss: 2.2082, Perplexity: 9.09968\n",
      "Epoch [3/3], Step [500/6471], Loss: 1.9159, Perplexity: 6.79333\n",
      "Epoch [3/3], Step [600/6471], Loss: 1.9503, Perplexity: 7.03107\n",
      "Epoch [3/3], Step [700/6471], Loss: 1.9001, Perplexity: 6.68673\n",
      "Epoch [3/3], Step [800/6471], Loss: 1.9684, Perplexity: 7.15955\n",
      "Epoch [3/3], Step [900/6471], Loss: 1.9113, Perplexity: 6.76179\n",
      "Epoch [3/3], Step [1000/6471], Loss: 2.3185, Perplexity: 10.1605\n",
      "Epoch [3/3], Step [1100/6471], Loss: 2.2027, Perplexity: 9.04932\n",
      "Epoch [3/3], Step [1200/6471], Loss: 1.9960, Perplexity: 7.35940\n",
      "Epoch [3/3], Step [1300/6471], Loss: 1.9332, Perplexity: 6.91184\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.6948, Perplexity: 14.8031\n",
      "Epoch [3/3], Step [1500/6471], Loss: 1.9439, Perplexity: 6.98579\n",
      "Epoch [3/3], Step [1600/6471], Loss: 1.9173, Perplexity: 6.80244\n",
      "Epoch [3/3], Step [1700/6471], Loss: 2.0932, Perplexity: 8.11098\n",
      "Epoch [3/3], Step [1800/6471], Loss: 1.8817, Perplexity: 6.56473\n",
      "Epoch [3/3], Step [1900/6471], Loss: 2.3436, Perplexity: 10.4183\n",
      "Epoch [3/3], Step [2000/6471], Loss: 2.0966, Perplexity: 8.13856\n",
      "Epoch [3/3], Step [2100/6471], Loss: 2.0723, Perplexity: 7.94355\n",
      "Epoch [3/3], Step [2200/6471], Loss: 2.0982, Perplexity: 8.15130\n",
      "Epoch [3/3], Step [2300/6471], Loss: 2.1037, Perplexity: 8.19653\n",
      "Epoch [3/3], Step [2400/6471], Loss: 1.7347, Perplexity: 5.66719\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.2689, Perplexity: 9.66860\n",
      "Epoch [3/3], Step [2600/6471], Loss: 1.9241, Perplexity: 6.84916\n",
      "Epoch [3/3], Step [2700/6471], Loss: 2.4376, Perplexity: 11.4457\n",
      "Epoch [3/3], Step [2800/6471], Loss: 1.8845, Perplexity: 6.58327\n",
      "Epoch [3/3], Step [2900/6471], Loss: 2.0055, Perplexity: 7.42992\n",
      "Epoch [3/3], Step [3000/6471], Loss: 1.9543, Perplexity: 7.05891\n",
      "Epoch [3/3], Step [3100/6471], Loss: 2.0631, Perplexity: 7.87055\n",
      "Epoch [3/3], Step [3200/6471], Loss: 2.0661, Perplexity: 7.89428\n",
      "Epoch [3/3], Step [3300/6471], Loss: 2.0200, Perplexity: 7.53834\n",
      "Epoch [3/3], Step [3400/6471], Loss: 1.9568, Perplexity: 7.07673\n",
      "Epoch [3/3], Step [3500/6471], Loss: 1.8998, Perplexity: 6.68482\n",
      "Epoch [3/3], Step [3600/6471], Loss: 1.9121, Perplexity: 6.76747\n",
      "Epoch [3/3], Step [3700/6471], Loss: 1.9174, Perplexity: 6.80350\n",
      "Epoch [3/3], Step [3800/6471], Loss: 2.0340, Perplexity: 7.64452\n",
      "Epoch [3/3], Step [3900/6471], Loss: 1.9588, Perplexity: 7.09079\n",
      "Epoch [3/3], Step [4000/6471], Loss: 2.1093, Perplexity: 8.24250\n",
      "Epoch [3/3], Step [4100/6471], Loss: 2.1798, Perplexity: 8.84468\n",
      "Epoch [3/3], Step [4200/6471], Loss: 2.1032, Perplexity: 8.19246\n",
      "Epoch [3/3], Step [4300/6471], Loss: 2.1601, Perplexity: 8.67227\n",
      "Epoch [3/3], Step [4400/6471], Loss: 1.9301, Perplexity: 6.89016\n",
      "Epoch [3/3], Step [4500/6471], Loss: 2.0797, Perplexity: 8.00247\n",
      "Epoch [3/3], Step [4600/6471], Loss: 1.9101, Perplexity: 6.75383\n",
      "Epoch [3/3], Step [4700/6471], Loss: 2.0356, Perplexity: 7.65726\n",
      "Epoch [3/3], Step [4800/6471], Loss: 1.8754, Perplexity: 6.52315\n",
      "Epoch [3/3], Step [4900/6471], Loss: 2.0989, Perplexity: 8.15727\n",
      "Epoch [3/3], Step [5000/6471], Loss: 2.3096, Perplexity: 10.0701\n",
      "Epoch [3/3], Step [5100/6471], Loss: 1.9393, Perplexity: 6.95409\n",
      "Epoch [3/3], Step [5200/6471], Loss: 2.1707, Perplexity: 8.76446\n",
      "Epoch [3/3], Step [5300/6471], Loss: 2.0697, Perplexity: 7.92287\n",
      "Epoch [3/3], Step [5400/6471], Loss: 1.8586, Perplexity: 6.41498\n",
      "Epoch [3/3], Step [5500/6471], Loss: 2.0414, Perplexity: 7.70145\n",
      "Epoch [3/3], Step [5600/6471], Loss: 2.0380, Perplexity: 7.67539\n",
      "Epoch [3/3], Step [5700/6471], Loss: 2.0317, Perplexity: 7.62720\n",
      "Epoch [3/3], Step [5800/6471], Loss: 2.0787, Perplexity: 7.99413\n",
      "Epoch [3/3], Step [5900/6471], Loss: 2.0301, Perplexity: 7.61504\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.9012, Perplexity: 6.69363\n",
      "Epoch [3/3], Step [6100/6471], Loss: 2.0705, Perplexity: 7.92911\n",
      "Epoch [3/3], Step [6200/6471], Loss: 2.0855, Perplexity: 8.04895\n",
      "Epoch [3/3], Step [6251/6471], Loss: 1.9252, Perplexity: 6.85635"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
